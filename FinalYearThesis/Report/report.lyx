#LyX 1.5.5 created this file. For more info see http://www.lyx.org/
\lyxformat 276
\begin_document
\begin_header
\textclass report
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\paperfontsize 12
\spacing onehalf
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
pagestyle{empty}
\end_layout

\begin_layout Standard


\backslash
newpage
\end_layout

\begin_layout Standard


\backslash
begin{center}
\end_layout

\begin_layout Standard


\backslash
begin{LARGE}
\end_layout

\begin_layout Standard

Fast User-level Inter-thread Communication, Synchronisation and Streaming
\end_layout

\begin_layout Standard


\backslash
end{LARGE}
\end_layout

\begin_layout Standard


\backslash
end{center}
\end_layout

\begin_layout Standard


\backslash
vspace{1in}
\end_layout

\begin_layout Standard


\backslash
begin{center}
\end_layout

\begin_layout Standard


\backslash
includegraphics[scale=0.3]{uom}
\end_layout

\begin_layout Standard


\backslash
end{center}
\end_layout

\begin_layout Standard


\backslash
begin{center} 
\end_layout

\begin_layout Standard


\backslash
begin{large} A thesis submitted in partial fulfilment of the requirements
 for the degree of Bachelor of Science (Hons)
\end_layout

\begin_layout Standard


\backslash
end{large}
\end_layout

\begin_layout Standard


\backslash
end{center}
\end_layout

\begin_layout Standard


\backslash
begin{center} 
\end_layout

\begin_layout Standard


\backslash
begin{large}University of Malta 
\backslash

\backslash
 Department of Computer Science
\end_layout

\begin_layout Standard


\backslash
end{large}
\end_layout

\begin_layout Standard


\backslash
end{center}
\end_layout

\begin_layout Standard


\backslash
vspace{2in}
\end_layout

\begin_layout Standard


\backslash
begin{center}
\end_layout

\begin_layout Standard


\backslash
begin{large} By 
\backslash

\backslash
 Li Lin 
\backslash

\backslash
 May 2008
\backslash
end{large}
\end_layout

\begin_layout Standard


\backslash
end{center}
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard


\backslash
newpage 
\end_layout

\begin_layout Standard


\backslash
pagestyle{plain}
\end_layout

\begin_layout Standard


\backslash
pagenumbering{roman} 
\end_layout

\begin_layout Standard


\backslash
setcounter{page}{1}
\end_layout

\begin_layout Standard


\backslash
begin{abstract}
\end_layout

\begin_layout Standard

Since 2000, the fast user-level thread scheduler SMASH has been actively
 developed at the University of Malta.
 This project's objective is to design and implement several user-level
 inter-thread communication constructs for SMASH.
 Since communication and synchronization among threads in a process is heavily
 used in most multi-threading programs, the efficiency of inter-thread communica
tions affects the efficiency of the whole program.
 In the past, those communication and synchronization constructs were built
 with locks, but this lock-based approach has some problems such as potential
 deadlock(or livelock), starvation and priority inversion.
 In order to solve these problems, lock-free algorithms were invented.
 A concurrent algorithm is lock-free, if after a finite step of execution,
 at least one of the participating threads is guaranteed to progress.
 Recently there is a lot of interest in lock-free algorithms in the research
 community.
 In this project, all the inter-thread communication constructs considered
 have two implementations: the lock-based implementation and the lock-free
 implementation.
 The performance of concurrent programs using these user-level constructs
 is measured and compared with the performance of programs using kernel-level
 inter-thread communication constructs.
 Besides, the differences between the lock-based implementations and lock-free
 implementations are also analyzed.
\end_layout

\begin_layout Standard


\backslash
end{abstract}
\end_layout

\begin_layout Standard


\backslash
section*{Acknowledgments}
\end_layout

\begin_layout Standard

I would like to experss my gratitude to my supervisor Dr.
 Kevin Vella who guided me to the final goal.
 It was his knowledge and patience that enabled me to complete this proejct
 successfully.
 During this project, Mr.
 Alan Casar helped me a lot so that I was able to understand SMASH in a
 very short time and Mr.
 Reggie Cushing gave me a lot of help in the hardware issues.
 So I would also like to give my thank to them for their assistance.
\end_layout

\begin_layout Standard


\backslash
tableofcontents{}
\end_layout

\begin_layout Standard


\backslash
listof{algorithm}{List of Algorithms}
\end_layout

\begin_layout Standard


\backslash
listoffigures
\end_layout

\begin_layout Standard


\backslash
newpage 
\end_layout

\begin_layout Standard


\backslash
pagestyle{plain}
\end_layout

\begin_layout Standard


\backslash
pagenumbering{arabic} 
\end_layout

\begin_layout Standard


\backslash
setcounter{page}{1}
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Standard
SMASH
\begin_inset LatexCommand cite
key "16"

\end_inset

 is a user-level thread system running on top of Linux.
 Originally, it was developed by Kurt Debattista in 2001 on Linux 2.2 series
 kernels.
 Since then it has been actively developed at the University of Malta by
 several students.
 By the time of this writing, a lot of work has been done.
 Now it runs on Linux 2.6 series kernels and has six different implementations.
 However, it still lacks user-level inter-thread communication and synchronizati
on constructs such as mutexes, semaphores, etc.
 The only inter-thread communication construct it has is the simple communicatio
n channel.
 The main objective of this final year project is to implement a inter-thread
 communication library for a particular implementation of SMASH, and to
 find out how these constructs affect the performance of the SMASH system.
 Since these constructs are shared objects among threads, to guarantee the
 consistency of these objects, certain synchronization mechanisms have to
 be used.
 When implementing these synchronization algorithms, there are two approaches:
 the lock-based approach and the lock-free approach.
 In lock-based algorithms, critical sections are protected by some forms
 of locks.
 A typical example is the spin lock, which is widely used on SMP systems
\begin_inset LatexCommand cite
key "5"

\end_inset

.
 In this project, all lock-based designs use spin locks.
 Lock-free algorithms are also exploited.
 Although lock-free and wait-free algorithms have drawn a lot of attention
 in the last decade, they are not heavily used in thread scheduling and
 inter-thread communications, instead, a lot of effort was made to develop
 general lock-free and wait-free ADTs.
 In this project, all user-level inter-thread communication constructs have
 their corresponding lock-free or wait-free implementations.
 
\end_layout

\begin_layout Standard
Lock-based algorithms are relatively easier to design, in the simplest case,
 one can just use a spin lock to surround the entire execution of the algorithm
 to guarantee its atomicity.
 However, this approach usually introduces extra overhead because a thread
 may have to wait even if the thread executing the algorithm is in the entry
 section or exit section, so for efficiency sake, the granularity of critical
 sections should be kept small.
 The extreme case is the lock-free algorithm, in which the size of critical
 sections are reduced to just single atomic instructions.
 The drawback of this approach is that fine-grained algorithms are difficult
 to design, and also difficult to reason with.
 
\end_layout

\begin_layout Section
The structure of this documentation
\end_layout

\begin_layout Standard
In Chapter 2, background knowledge about SMP systems, lock-free algorithms,
 processes and threads is given, then Chapter 3 gives a literature review
 on interprocess communication constructs on different systems.
 In this chapter, two kinds of operating systems are mentioned: systems
 with monolithic kernels and ones with microkernels.
 In Chapter 4, we will discuss the implementation of the inter-thread communicat
ion constructs for SMASH.
 Results for the performance of these constructs are given and discussed
 in Chapter 5.
\end_layout

\begin_layout Chapter
Background
\end_layout

\begin_layout Section
SMP systems
\end_layout

\begin_layout Standard
Symmetric Multiprocessing
\begin_inset LatexCommand cite
key "5"

\end_inset

 is a computer architecture in which a set of identical CPUs are connected
 together though a shared memory bus so that they can co-operate to get
 more computational power.
 Each CPU has its own caches and registers, but the main memory of the system
 is shared amongst all CPUs and access to the main memory is uniform, i.e.
 the access time to a memory location is the same for all CPUs in the system,
 this model is called Uniform Memory Access(UMA)
\begin_inset LatexCommand cite
key "5"

\end_inset

.
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Architecture of SMP
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~

\begin_inset Graphics
	filename SMP_arch.eps
	scale 70

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset

 Another memory model is the Non-Uniform Memory Access model, in which CPUs
 have their own memory and each CPU can access other CPU's local memory,
 but in that case, the access is relatively slow.
 In order to utilize this architecture, a program has to be subdivided into
 several parts that can be processed independently, so that these parts
 can be executed on different CPUs concurrently.
 
\end_layout

\begin_layout Section
Synchronization support
\end_layout

\begin_layout Standard
On SMP systems, different CPUs usually have to access some shared data concurren
tly.
 In order to guarantee the consistency of the shared data, we need some
 kind of synchronization mechanisms.
 Modern architectures offer some atomic instructions which allow us to implement
 those high-level synchronization algorithms.
 We list some of these atomic instructions.
\end_layout

\begin_layout Subsection*
Test_And_Set
\end_layout

\begin_layout Standard
This instruction atomically check whether the value stored in a memory location
 is true or not.
 If the value is false, then it changes the value to true, otherwise it
 does nothing.
 
\begin_inset Float algorithm
placement h
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Pseudo code for 
\emph on
Test_And_Set
\end_layout

\end_inset


\end_layout

\begin_layout Standard
TestAndSet(var) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(var == false)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
var = true;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return true;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return false;
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Fetch_And_Add
\end_layout

\begin_layout Standard
This instruction reads the value from a given memory location and increments
 the value in that location by a number given by the user.
 
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Pseudo code for 
\emph on
Fetch_And_Add
\end_layout

\end_inset


\end_layout

\begin_layout Standard
FetchAndAdd(void * location, int num) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
int old = *location
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
*location = *location + num
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return old
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Swap
\end_layout

\begin_layout Standard
The 
\emph on
Swap 
\emph default
atomically exchanges the values stored in two memory places, these places
 can be locations in the main memory or registers.
 A typical implementation is given by Algorithm
\emph on
 
\emph default

\begin_inset LatexCommand ref
reference "alg:Swap"

\end_inset

, but in our case, we slightly modify the implementation for convenience's
 sake.
 Our implementation is given by Algorithm
\emph on
 
\emph default

\begin_inset LatexCommand ref
reference "alg:The-semantics-of"

\end_inset

.
 
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard

\emph on
\begin_inset LatexCommand label
name "alg:Swap"

\end_inset

Swap
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Swap(void * location1, void * location2) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
tmp_value = *location1
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
*location1 = *location2
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
*location2 = tmp_value
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "alg:The-semantics-of"

\end_inset

The semantics of our implementation for swap
\end_layout

\end_inset


\end_layout

\begin_layout Standard
long swap(long * location, long value) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
long tmp_value = *location
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
*location = value
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return tmp_value
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Compare_And_Swap
\end_layout

\begin_layout Standard

\emph on
Compare_and_Swap
\emph default
 works in the way as Algorithm
\emph on
 
\emph default

\begin_inset LatexCommand ref
reference "alg:Pseudo-code-for"

\end_inset

 shown: it compares the content of a given memory location with its old
 value which is read some time before, if the content is the same as the
 old value, then it writes the new value to the memory and returns TRUE,
 otherwise, it does nothing to that memory and returns FALSE.
 The whole process is atomic.
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "alg:Pseudo-code-for"

\end_inset

Pseudo code for 
\emph on
Compare_and_Swap
\end_layout

\end_inset


\end_layout

\begin_layout Standard
bool CAS(Location, old, new) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if (location == old)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
location=new
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return true
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else return false
\end_layout

\end_inset

According to 
\begin_inset LatexCommand cite
key "20"

\end_inset

, 
\emph on
Compare_And_Swap
\emph default
 was first implemented in the IBM System 370, and now it is widely supported
 on many architectures, for example x86-32, x86-64, Sun Sparc etc.
\end_layout

\begin_layout Subsection*
Linked-Load/Store-Conditional(
\emph on
LL/SC
\emph default
)
\end_layout

\begin_layout Standard

\emph on
LL/SC
\emph default
 works as follows: the instruction 
\emph on
LL
\emph default
 first reads the content from a memory location, then 
\emph on
SC
\emph default
 can be used to update the memory location.
 If the content of that memory has not been changed, then the new value
 is stored into the memory and 
\emph on
SC
\emph default
 returns 
\emph on
TRUE
\emph default
.
 Otherwise the memory is not updated and 
\emph on
SC
\emph default
 returns 
\emph on
FALSE
\emph default
.
 However, in practice, no architectures that support 
\emph on
LL/SC
\emph default
 such as Alpha, MIPS, PowerPC, etc, implement the full semantics of 
\emph on
LL/SC
\emph default
 in hardware in the sense that memory accesses inbetween 
\emph on
LL
\emph default
 and 
\emph on
SC
\emph default
 is restricted, for example none of these architectures allow nesting or
 interleaving of 
\emph on
LL/SC
\emph default
 pairs.
 Besides, on some platforms, context switches, another 
\emph on
LL
\emph default
 operation or even another 
\emph on
load
\emph default
 or 
\emph on
write
\emph default
 operations may cause 
\emph on
LL/SC
\emph default
 to fail spuriously.
 This instruction is available on systems like MIPS and PowerPC.
\end_layout

\begin_layout Section
Spin locks
\end_layout

\begin_layout Standard
On uniprocessor systems, an execution sequence can be combined together
 so that it is not interruptable by disabling the interrupt of the CPU at
 the beginning of the sequence and re-enabling the interrupt at the end.
 However, this mechanism is not valid on SMP systems, because we can only
 disable the interrupts on some CPU locally, other CPUs can still access
 the critical section.
 In this case, spin locks are used to protect critical sections.
 A spin lock can take one of two values: the integer 1 to denote the lock
 is locked, 0 to denote it is free.
 When the spin lock is 1, other CPUs trying to obtain the lock just keep
 looping until it is released.
 Algorithm 
\begin_inset LatexCommand ref
reference "alg:Pseudo-code-of"

\end_inset

 gives the pseudo code.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "alg:Pseudo-code-of"

\end_inset

Pseudo code of Spin locks
\end_layout

\end_inset


\end_layout

\begin_layout Standard
L1\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
getSpinlock(int lock) {
\end_layout

\begin_layout Standard
L2\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
while(lock == 1);
\end_layout

\begin_layout Standard
L3\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
lock = 1;
\end_layout

\begin_layout Standard
L4\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}
\newline

\end_layout

\begin_layout Standard
L5\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(int lock) {
\end_layout

\begin_layout Standard
L6\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
lock = 0;
\end_layout

\begin_layout Standard
L7\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
However, to implement the above semantics, special atomic instructions are
 needed, because there is a danger between L2 and L3.
 When the lock is released at L2 and before it is locked again by another
 thread at L3, it is possible that more than one thread has finished L2,
 and as a result, more than one thread will enter the critical section.
 Hence, we need an instruction to implement L2 and L3 atomically.
 
\emph on
Test_and_Set
\emph default
 is this kind of instruction.
 It tests whether the content of a shared variable is true or not, if false,
 it sets the variable to true, otherwise it does nothing.
 The entire process is done atomically.
 Then spin locks can be implemented properly with it.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Proper implementation for spin locks
\end_layout

\end_inset


\end_layout

\begin_layout Standard
getSpinlock(int * lock) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
while(TestAndSet(lock));
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard
releaseSpinlock(int * lock) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
*lock = 0;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Although the above implementation is correct, it has another problem.
 When multiple threads are trying obtain the spin lock, the memory where
 the lock is stored becomes a hot-spot, because all threads keep accessing
 it.
 In this case, we will have high memory contention.
 In order to avoid this problem, we can use 
\emph on
Test_Test_and_Set,
\emph default
 the basic idea is that a thread uses 
\emph on
Test_And_Set
\emph default
 to change the value of the spin lock, if it has been locked by another
 thread, instead of spinning on the variable directly, it spins on a local
 copy of the lock in its local cache, when the lock is released, those copies
 stored in CPU's local cache will be invalidated automatically by the cache
 coherence mechanism, CPUs will re-read the value of the lock into their
 local cache.
 In the way, the waiting threads do not access the memory during spin-waiting,
 instead, they just access the copy in the local CPU cache, hence the memory
 contention is reduced.
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Spin lock with 
\emph on
Test_Test_And_Set
\end_layout

\end_inset


\end_layout

\begin_layout Standard
getSpinlock(int * lock) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
while(*lock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
while(TestAndSet(lock));
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
while(*lock);
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard
releaseSpinlock(int * lock) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
*lock = 0;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Another problem of spin locks is that it is unfair, i.e.
 some threads may be delayed for a long time even they come earlier.
 Because there is no ordering among those waiting threads, they just spin-wait
 for the lock to be freed.
 It is nondeterministic that who will get the lock.
 This will cause high latency on some threads.
 The MCS-lock
\begin_inset LatexCommand cite
key "13"

\end_inset

 solves this problem by enforcing a FIFO ordering.
 Linux developers used another algorithm called 
\emph on
ticket spin lock
\emph default
 to provide the FIFO ordering for spin locks.
 This algorithm is an adoption of the 
\emph on
Ticket algorithm
\emph default

\begin_inset LatexCommand cite
key "6,17"

\end_inset


\emph on
.

\emph default
 On a system with a small number of CPUs, the ticket spin lock performs
 better, because it is less complicated, but it still suffers from the memory
 contention problem.
 On the other hand, The MCS-lock performs better in a system with a large
 number of CPUs, because it utilizes the local cache of each CPU.
 A CPU just spin-waits on a variable stored in its local cache, hence the
 contention caused by busy-waiting is avoided.
\end_layout

\begin_layout Section
Lock-free algorithms
\end_layout

\begin_layout Standard
There are some problems with lock-based algorithms.
 First, there are potential dead(or live) locks.
 A dead lock is a situation in which all thread wait for one another cyclically,
 but no one is in the critical section.
 As a result, they all wait forever, if they are busy-waiting, then we call
 it a live lock.
 Second, priority inversion happens when a high priority thread tries to
 acquire the lock which is currently held by a low priority thread, so the
 former one has to wait until the latter releases the lock.
 This may cause serious problem on real-time systems.
 The third problem is convoy effect.
 
\end_layout

\begin_layout Standard
To overcome these problems, lock-free algorithms are used.
 A concurrent algorithm is lock-free if after a finite number of execution
 steps, at least one of the participating threads progresses to the final
 goal.
 Lock-free algorithms are free of dead locks, but some particular threads
 may be delayed indefinitely.
 A stronger concept is the wait-free algorithms.
 An algorithm is wait-free if after a finite number of steps, all participating
 threads can finish.
\end_layout

\begin_layout Standard
Normally, wait-free algorithms are more efficient, however, they are hard
 to find.
 Currently most of wait-free algorithms are based on some strong assumptions
 such as fixing number of participating threads before the execution.
 Hence they are quite restricted.
\end_layout

\begin_layout Standard
Implementing these lock-free algorithms also needs some special atomic instructi
on supported by the hardware.
 The most commonly used instructions are 
\emph on
Compare_and_Swap
\emph default
, and 
\emph on
Link-Load/Store-Conditional.
 
\emph default
Herlihy
\begin_inset LatexCommand cite
key "25"

\end_inset

 has proved that both 
\emph on
CAS
\emph default
 and 
\emph on
LL/SC
\emph default
 are powerful enough to construct most lock free data structures shared
 by more than two threads but 
\emph on
Fetch_And_Add
\emph default
, 
\emph on
Test_And_Set
\emph default
 and 
\emph on
Swap
\emph default
 are not.
 And even some more sophisticated atomic structures like atomic stack operations
 are not enough, which is quite surprising because these operations are
 quite powerful.
 In 
\begin_inset LatexCommand cite
key "19"

\end_inset

, a software level lock-free 
\emph on
LL/SC
\emph default
 with full semantics was implemented with 
\emph on
CAS
\emph default
 provided by the hardware.
\end_layout

\begin_layout Subsection
ABA problem
\end_layout

\begin_layout Standard
When implementing lock free data structures by using 
\emph on
CAS
\emph default
, one critical issue is the ABA problem.
 It is described as follows: Suppose a thread 
\emph on
A
\emph default
 reads data from a memory location 
\emph on
l
\emph default
, then tries to update the content of 
\emph on
l
\emph default
 by using 
\emph on
CAS
\emph default
.
 But after 
\emph on
A
\emph default
 has read the value and before the update happens, another thread 
\emph on
B
\emph default
 first changed the content of 
\emph on
l
\emph default
 then changed it back to its original value.
 Then when 
\emph on
A
\emph default
 tries to update the content of 
\emph on
l
\emph default
 by using 
\emph on
CAS
\emph default
, it will success without noticing what 
\emph on
B
\emph default
 has done.
 This problem was first identified on the IBM System 370
\begin_inset LatexCommand cite
key "7"

\end_inset

 and may lead to data corruption.
 
\emph on
LL/SC
\emph default
 would not suffer from this problem if its full semantics were implemented.
 However, due to practical reasons, no hardware has ever implemented 
\emph on
LL/SC
\emph default
 with its full semantics, so existing implementations of
\emph on
 LL/SC
\emph default
 also has this problem.
 The most efficient way to solve the ABA problem is to use 
\emph on
CAS2
\emph default
(or Double Compare_And_Swap), which is basic the same as 
\emph on
CAS
\emph default
 but keeps a count of the number of times a memory location is modified,
 hence solving the ABA problem.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement h
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Pseudo code for 
\emph on
CAS2
\end_layout

\end_inset


\end_layout

\begin_layout Standard
boolean CAS2(var,count,old-value,old-count,new-value) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(var == old-value AND count == old-count)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
var = new-value;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
count++;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return TRUE;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else return FALSE;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
On 32-bit machines, 
\emph on
CAS2
\emph default
 operates on 8 bytes atomically so that users can use 4 bytes as data to
 be updated and the other 4 bytes as the update counter.
 However, on some 64bit machines, to implement 
\emph on
CAS2
\emph default
, one needs atomic machine code instructions that operate on 16 bytes which
 are not available on these CPUs, hence this technique can not be applied
 in such cases.
\end_layout

\begin_layout Standard
A second solution is to use hazard pointers designed by Michael
\begin_inset LatexCommand cite
key "1,19,20"

\end_inset

.
 The basic idea of this approach is that each thread holds a set of one-writer
 multiple-reader pointers called hazard pointers.
 Only the owner thread can write to them, others can only read them.
 When a thread accesses a memory location, it makes one of its hazard pointers
 point to that location.
 When a thread tries to recycle the memory, it searches all hazard pointers
 owned by other threads to check whether some threads are still using the
 memory, and the memory will not be recycled until no threads use it any
 more.
 In this way, the ABA problem is avoided.
\end_layout

\begin_layout Standard
The third way is to use some lock-free reference counting algorithms for
 example, Valois' lock-free reference counting algorithm
\begin_inset LatexCommand cite
key "12"

\end_inset

.
 The core idea is that each piece of memory participating in the lock-free
 data structure contains a counter, and any thread referencing the memory
 location will increment the counter.
 After use, the counter will be decremented and the memory will not be recycled
 until the counter is zero.
 
\end_layout

\begin_layout Subsection
Lock-free First In First Out queues
\end_layout

\begin_layout Standard
In this project, the most commonly used data structures are First In First
 Out queues.
 They are used as message queues and waiting queues for semaphores and mutexes.
 Michael and Scott developed a lock-free FIFO queue
\begin_inset LatexCommand cite
key "18"

\end_inset

, which Debtattista used in one of the SMASH implementations.
 However, he showed that its performance was not as good as expected, and
 suggested in 
\begin_inset LatexCommand cite
key "16"

\end_inset

 that the main problems may be the memory management and the extensive use
 of the 
\emph on
CAS
\emph default
 instruction which is relatively costly.
 There are many other lock free FIFO queue designs which trying to improve
 the performance.
 We used a design from 
\begin_inset LatexCommand cite
key "2"

\end_inset

, which by experiments
\begin_inset LatexCommand cite
key "2"

\end_inset

 is almost twice faster than MS-queue in most cases.
 Another problem that causes performance degradation is that 
\emph on
CAS
\emph default
,
\emph on
 LL/SC
\emph default
 and 
\emph on
CAS2
\emph default
 are costly, and they are used intensively in enqueue- and dequeue-operations.
 In fact, for most cases, the use of these expensive instructions are redundant,
 since errors rarely happen, hence some work has been done to try to reduce
 the frequency of use of these instructions.
 Some notable works are 
\begin_inset LatexCommand cite
key "3"

\end_inset

 and 
\begin_inset LatexCommand cite
key "24"

\end_inset

, in which developers implemented a lock-free FIFO queue as a double-linked
 list and only one 
\emph on
CAS
\emph default
 is used in the enqueue operation, whenever an error is detected, an auxiliary
 function is used to fix it.
 Although the error-fixing is complicated and more expensive than 
\emph on
CAS
\emph default
, the queue still performs much better than those queues which require intensive
 use of 
\emph on
CAS
\emph default
.
 So far we have not found any linked list-based wait-free FIFO queues for
 a scheduler like SMASH.
 There are some wait-free FIFO queues available, but they are either array-based
 or else they depend on special scheduling policies.
\end_layout

\begin_layout Section
Processes, kernel and user-level threads
\end_layout

\begin_layout Standard
Multitasking plays a critical role in most general purpose operating systems.
 At first, Unix systems implemented multitasking by using the concept of
 processes.
 A process is a running instance of a program which has its own set of resources
 such as address spaces, registers, open file descriptors and so on.
 The system creates multiple processes then schedules among them so that
 users get the impression that multiple programs are running concurrently.
 The main problem of this approach is that the context switch between two
 processes is very expensive.
 To switch from a process to another, the system has to do a lot of tasks
 like switching from user mode to kernel mode, saving the current registers
 used by the process and changing the address space because each process
 has its own virtual memory space.
 In addition, communications between processes is also expensive, because
 messages have to be copied from the address space of one process to that
 of another process, although there are techniques like Shared Memory and
 COW(Copy On Write)
\begin_inset LatexCommand cite
key "31"

\end_inset

 that can be used to reduce this kind of overhead, in many cases, message
 copying is still necessary.
 Besides, inter-process communication usually implies context switches between
 processes, which are costly in their own right.
 To overcome this problem, the concept of a thread or LWP (Light Weight
 Process) was introduced.
 Threads within a process can be scheduled by the system just like the system
 schedules processes, but they share a lot of resources, for example, threads
 within a process have no private address space, therefore context switches
 between threads are cheaper.
 Also communications between threads are cheaper and easier to implement
 due to the fact that threads share a single address space.
 
\end_layout

\begin_layout Standard
There are two kind of threads: kernel threads and user level threads.
 Kernel threads are implemented in the kernel, i.e.
 when such a thread is created, the kernel maintains all kind of information
 about it.
 This kind of threads is normally preemptive.
 However, the context switch is a bit expensive, because the information
 about a thread is maintained by the kernel, to do the context switch, the
 program has to switch from user mode to kernel mode and save the current
 status of the thread execution like content of registers, program counter,
 stack pointer into the data structure representing the thread, but switching
 from user mode to kernel mode is expensive.
 In addition, to preempt a running thread, the content of all registers
 has to be saved because we do not know which registers are currently being
 used by the thread, and this operation is particularly expensive on RISC
 CPUs since they normally have a large set of registers.
 In some systems like Mach
\begin_inset LatexCommand cite
key "26,29,31"

\end_inset

 and Windows, the notion of processes is quite different from the traditional
 one from UNIX, as processes in these systems are just running contexts
 or environments in which kernel threads run.
 For example in the Mach system, once a process, which are also named 
\emph on
tasks 
\emph default
in Mach, is created, the system has to create a so called main thread in
 the process.
\end_layout

\begin_layout Standard
User level threads, as the name suggests, are threads implemented in user
 space, the kernel has no information about them, hence they are non-preemptive,
 but cooperative.
 Hence, a running thread has to release the CPU explicitly so that other
 user-level thread can run.
 The advantage is that the system is able to know that what registers are
 being used by the thread, therefore only a subset of registers need to
 be saved.
 Hence, user level threads are normally faster than kernel level threads.
 In fact, SMASH
\begin_inset LatexCommand cite
key "16"

\end_inset

 applied this technique and reduced the time of context switch to roughly
 
\emph on
28ns
\emph default

\begin_inset LatexCommand cite
key "16"

\end_inset


\emph on
.

\emph default
 Another advantage of user-level thread is that the scheduler also runs
 in user space, hence scheduling between threads does not need to go from
 user mode to kernel mode.
 There are many implementations of user level threads, for example Mach's
 cthreads
\begin_inset LatexCommand cite
key "26,31"

\end_inset

, pthreads on early versions of FreeBSD and SMASH.
\end_layout

\begin_layout Subsection
SMASH
\end_layout

\begin_layout Standard
SMASH
\begin_inset LatexCommand cite
key "16"

\end_inset

 is a user level thread system.
 It uses the two-level thread scheduling model.
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Two Level thread scheduling
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename two-level-scheduling.eps

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset

 The basic idea is to create a set of user level threads on top of different
 kernel threads.
 The main advantage of this approach is that when a user-level thread is
 blocked for some reasons, other user-level threads on top of different
 kernel threads can still run.
 SMASH is partially based on another user-level thread scheduler called
 MESH developed by Boosten
\begin_inset LatexCommand cite
key "22,23"

\end_inset

 and SMP-MESH developed by Cordina
\begin_inset LatexCommand cite
key "11"

\end_inset

, it is actively being developed in the university of Malta.
 In 2000, Based on MESH, Joseph Cordina developed SMP-MESH as his Final
 Year Project, his implementation of SMP-MESH used a shared run queue which
 is protected by spin locks.
 Then in 2001, Debattista wrote SMASH based on Cordina's work as his master
 degree.
 He designed the uniprocessor version of SMASH and the SMP versions.
 He came up with six different designs for the SMP version of SMASH, which
 can be categorized into two main categories: SMASH with shared run queue
 and SMASH with per-CPU-run-queue.
 SMASH runs on both uniprocessor and SMP machines, the internal implementations
 are quite different, the uniprocessor version is purely cooperative, in
 a running SMASH instance, there is only one thread scheduler running in
 the user space and all SMASH threads are scheduled by it.
 A thread has to yield the CPU explicitly so that other threads can run.
 On the other hand, the SMP version take the benefit of multi-CPUs, it creates
 one thread scheduler running on top of a kernel thread for each CPU.
 SMASH threads on the same CPU are cooperative, however, on the whole system
 they are preemptive, i.e.
 if SMASH threads on different CPUs are accessing some shared data, some
 of them may be preempted by the underlying kernel threads.
 For efficiency sake, kernel threads on which the SMASH schedulers run are
 bounded to the corresponding CPUs, hence even one of these kernel threads
 is scheduled by the kernel thread scheduler, it will be woken up on the
 same CPU.
 On Linux 2.2 series kernels, this kind of operation was not supported, so
 Debattista had to apply a patch to the Linux kernel he used, from Linux
 kernel 2.4 onwards, this operation can be done by a system call named 
\emph on
sched_setaffinity()
\emph default
, so Reggie Cushing patched SMASH so that it can run on Linux 2.4 systems,
 and then Alan Casar further patched it so that SMASH can run on Linux 2.6.
 
\end_layout

\begin_layout Standard
In this project, we used a SMASH implementation with shared run queue with
 fine-grained locks on a SMP system.
 With this implementation, we have one thread scheduler per processor running
 on top of a kernel thread.
 There is a single shared run queue among them.
 The run queue is implemented with Michael and Scott dual-lock FIFO queue
\begin_inset LatexCommand cite
key "18"

\end_inset

.
 Each scheduler will pick up a user-level thread from the shared run queue
 and run it.
 When a thread yields the CPU, it first saves the current context, then
 the thread is re-inserted onto the run queue.
 If the run queue is empty and one of the SMASH scheduler has no thread
 to run, then the underlying kernel thread on which the SMASH scheduler
 runs will sleep on a system semaphore, and it is woken up when a new job
 arrives.
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
The architecture of SMASH with shared run queue(from 
\begin_inset LatexCommand cite
key "14"

\end_inset

)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename shared.eps
	scale 70

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Interprocess communication and synchronization constructs
\end_layout

\begin_layout Standard
In modern operating systems such as UNIX and Windows, inter-process communicatio
ns play a crucial role since they are intensively used.
 In this chapter, we are going to give an overview on these constructs.
 
\end_layout

\begin_layout Section
System V IPC
\end_layout

\begin_layout Standard
System V 
\begin_inset LatexCommand cite
key "31"

\end_inset

is one of the major branches of UNIX systems
\begin_inset LatexCommand cite
key "31"

\end_inset

.
 It provides three kinds of interprocess communication constructs: semaphore,
 message queue and shared memory.
 These constructs are called System V IPC and influence heavily other UNIX/UNIX-
like systems.
 BSD systems and Linux also implement these constructs.
\end_layout

\begin_layout Subsection
Semaphores
\end_layout

\begin_layout Standard
Semaphores are described in 
\begin_inset LatexCommand cite
key "26,31"

\end_inset

.
 They contain a integer counter and support two atomic operations 
\emph on
signal
\emph default
 and 
\emph on
wait
\emph default
.
 The signal operation decrements the counter of the semaphore.
 If the result is non-negative, then the process continues its execution,
 otherwise, it blocks until other processes wake it up with the 
\emph on
wait 
\emph default
operation.
 The 
\emph on
signal
\emph default
 operation increments the counter and checks if there are any processes
 waiting for the semaphore.
 If so, it will wake one waiting process up.
\end_layout

\begin_layout Standard
Semaphores are used to provide some synchronization mechanisms among processes.
 One application is that they can be used to limit the number of processes
 accessing a shared resource, for example, a web server can use semaphores
 to control the number of clients accessing a particular page.
 Another important use is that when a semaphore is initialized to 1, it
 can be used to provide mutual exclusion to a critical section, in this
 case, only one process is able to access the shared resource, and other
 processes have to wait.
 
\end_layout

\begin_layout Standard
The semaphore is a very important interprocess communication construct and
 is widely used in concurrent programming.
 Semaphores are high level constructs, they are shared objects on their
 own, and to implement semaphores, one needs low level synchronization construct
s like spin locks.
 In fact, on Linux systems, system V semaphores are implemented in the kernel
 with spin locks, and on Linux systems, operations on semaphores always
 enter the kernel, operate on the semaphore and then return to the user
 space even if there is no contention on the semaphore, which is quite expensive.
 
\end_layout

\begin_layout Subsection
Message queues
\end_layout

\begin_layout Standard
A message queue
\begin_inset LatexCommand cite
key "21,31"

\end_inset

 is implemented as a linked list of individual messages located in the kernel.
 A message has a integer field as its type and a message body containing
 the actual data.
 To send a message to a message queue, a process has to hold the appropriate
 permissions, and the message is copied from the sender to the queue in
 the kernel, if the queue is full or the message is too large, then the
 process either blocks until the required space is available or it gets
 an error immediately.
 To receive messages from a message queue, a process also have the corresponding
 permissions.
 And the entire queue is searched for the specified type of messages, the
 first one found will be copied from the queue to the located that is pre-define
d then the message is removed from the queue.
 If no such messages are found, then the receiver can choose either blocks
 or returns immediately.
 
\end_layout

\begin_layout Section
Mach's IPCs
\end_layout

\begin_layout Standard
Traditionally, kernels of operating systems are monolithic, their components
 are highly coupled together and runs in kernel mode.
 The advantage of this approach is that it is very efficient, but as the
 kernel grows larger, it suffers from problem such as security and maintainabili
ty.
 Hence developers tried to move some functionality out of the kernel and
 to implement them as independent processes running in user mode, the kernel
 only provides some very basic services such as address spaces and IPCs,
 and the components communicate and cooperate with each other though interproces
s communication constructs.
 Therefore, the efficiency of the interprocess communication is very crucial
 on such systems since they are heavily used.
 Mach
\begin_inset LatexCommand cite
key "29,31"

\end_inset

 is such a microkernel implementation.
 
\end_layout

\begin_layout Standard
In Mach, only a very few components such as device drivers, task scheduler,
 etc, are implemented in the kernel, other components like Pager, File systems,
 etc are implemented in user space.
 All these components communicate with each other though ports.
 A port is an unidirectional bounded message queue in the kernel.
 Mach ensures security by the concept of 
\emph on
rights.
 
\emph default
A right has two parts: a port name and a capability on that port.
 There are two kinds of capabilities on a port: 
\emph on
send
\emph default
 which allows a process/thread send messages to a port, or 
\emph on
receive
\emph default
 which allows a process/thread receive messages from a port.
 For a given port, only one process can hold its 
\emph on
receive
\emph default
 capability, but there can be many processes/threads have the 
\emph on
send
\emph default
 capability on it.
 Since a port is a bounded queue, if a process tries to send a message to
 a port when it is full, the process either aborts immediately or it blocks
 until there is a space available in the queue.
 
\end_layout

\begin_layout Standard
A message has a fixed-length header and a variable-length message body.
 A message header contains information such as the destination port, the
 length of the message body, etc.
 A message body consists of different data sections, each section has its
 own type.
 In the past, messages are always copied from the sender to the receiver,
 but this is quite expensive when the message is large, therefore, from
 Mach 2.5, a technique called Copy On Write(COW) was used.
 With this technique, instead of copying the message, a sender just sends
 the pointer to the message body to the receiver, if the receiver just reads
 the message and does not modify it, no copy operation will happen at all.
 Of course, the details is more complicated and in reality, this is done
 though the virtual memory system.
\end_layout

\begin_layout Section
L4's IPCs
\end_layout

\begin_layout Standard
Mach was categorized as the first-generation microkernel, one of its critical
 problems is that its interprocess communications are too slow
\begin_inset LatexCommand cite
key "14"

\end_inset

.
 It was generally believed that it was the overhead caused by things like
 vertical switches, address space switches and memory penalties that made
 the IPC slow.
 However, later researches 
\begin_inset LatexCommand cite
key "8,9"

\end_inset

show that these kinds of overheads can be largely reduced by a proper kernel
 design.
 L4 family
\begin_inset LatexCommand cite
key "8,9"

\end_inset

 is a typical example of the second generation microkernels.
 It was developed at GMD in 1995.
 In the kernel, it only implements only three components: address spaces,
 threads and interprocess communication.
 
\end_layout

\begin_layout Standard
L4's IPC is done by message passing.
 Threads in address spaces communicate by sending messages.
 And the IPC is synchronous and unbuffered.
 
\emph on
Synchronous 
\emph default
means that until the sender and the receiver are both ready, the communication
 will not start, if one end is not ready, then the other end has to block.
 
\emph on
Unbuffered
\emph default
 means that there is not intermediate buffer between the sender and the
 receiver, a message is transferred directly from the address space of the
 sender to the address space of the receiver, but there can be buffers in
 both sender or receiver's address spaces that are used to store the message.
 
\end_layout

\begin_layout Standard
Messages can be transferred from one address space to another by using three
 ways depending on the type of the message.
 The first way is to transfer data though registers.
 This way is mainly for 
\emph on
In-line by-value
\emph default
 data, which has to be very small.
 Before the communication starts, this kind of messages have to be copied
 to a buffer in the sender's address space and be aligned, then the message
 is transferred though registers.
 The second way is to transfer a message by simply copying it from the sender
 to the receiver.
 This is used to transfer 
\emph on
strings.

\emph default
 The main advantage of this approach is that messages can be located anywhere
 in the memory and it can have arbitrary length.
 However, this way is inefficient if the message is either too small or
 too large.
 To send data as strings, one has to set up a 
\begin_inset Quotes eld
\end_inset

string dopes
\begin_inset Quotes erd
\end_inset

 to indicate the memory locations of the message both in the sender's space
 and the receiver's space(where it will be stored when the receiver gets
 it).
 This is relatively costly, so for a small amount of data, to send it as
 
\emph on
In-line
\emph default
 data is the most efficient way.
 On the other hand, if the message is too large, then the copying is expensive.
 In fact, L4 offers a better way to send a large amount of data than copying.
 
\end_layout

\begin_layout Standard
To send a large amount of data, it is better to use address space mappings
 which allow the pages where the messages are stored in the sender's address
 space be mapped to the address space of the receiver.
 L4 supports three address space mapping operations: 
\emph on
Grant
\emph default
, 
\emph on
Share
\emph default
 and 
\emph on
Flush.
 
\end_layout

\begin_layout Itemize

\emph on
Grant 
\emph default
maps any pages in an address space to another address space, the pages are
 removed from the old address space and is added to the target address space,
 hence the original owner of these pages can not access them any more.
\end_layout

\begin_layout Itemize

\emph on
Share 
\emph default
has a similar functionality with 
\emph on
Grant, 
\emph default
the difference is that if a piece of memory is mapped to another address
 space by 
\emph on
Share
\emph default
, it is still accessible to its original owner, because these pages are
 not removed from the original address space.
\end_layout

\begin_layout Itemize

\emph on
Flush 
\emph default
demaps a piece of memory that was mapped to other address spaces with 
\emph on
Grant
\emph default
 or 
\emph on
Share.
\end_layout

\begin_layout Standard
With the above operations, techniques like Copy On Write can be implemented
 for large data transfer, hence improve the efficiency of the IPC.
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
In this chapter, we gave a brief introduction to some IPC constructs in
 different operating systems.
 And inter-thread communications can be considered to be simplified cases
 of interprocess communications, because they both involve synchronization
 between concurrent executions.
 IPCs are more complicated because the communications are cross address
 spaces, in contrast, ITCs are simpler since the communication happen within
 the same address space.
 In the next chapter, we are going to discuss the designs and implementations
 of some widely used inter-thread communication constructs for SMASH.
\end_layout

\begin_layout Chapter
Design and Implementation
\end_layout

\begin_layout Section
Mutex
\end_layout

\begin_layout Standard
In this chapter, we will discuss the internal implementations of the mutex.
 We have two designs of mutexes for SMASH, the lock-based mutex and the
 lock-free mutex.
 Currently, SMASH does not have a user-level mutex implementation, as a
 result, one has to use pthread mutex or a spin lock when a mutex is needed.
 The main problem is that both ways will block the entire kernel thread
 on which the SMASH scheduler runs, and this will cause degradation in the
 overall performance.
 We implemented two user-level mutexes for SMASH so that they will only
 block some user-level threads, and while these threads are waiting for
 the resource to be freed, the scheduler can still run other threads which
 are ready.
 
\end_layout

\begin_layout Subsection
APIs of mutexes
\end_layout

\begin_layout Subsubsection*
GetMutex
\end_layout

\begin_layout Standard
The function is used to obtain a mutex.
 If the mutex is not free, it will block the calling user-level thread.
\end_layout

\begin_layout Subsubsection*
ReleaseMutex
\end_layout

\begin_layout Standard
This function is used to release a mutex.
 If there are threads waiting for the mutex, the function will wake up the
 first one in the waiting queue.
 
\end_layout

\begin_layout Subsubsection*
Cmutex_init
\end_layout

\begin_layout Standard
This function is used to initializes a mutex.
 Note that it does not create a new mutex structure, it just initialize
 existing one.
\end_layout

\begin_layout Subsection
General issues of mutex implementation
\end_layout

\begin_layout Standard
Generally speaking, a mutex should have a variable to denote the status
 of the mutex, i.e.
 whether it is free or not, and a waiting queue where waiting threads are
 blocked.
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
General data structure for a mutex
\end_layout

\end_inset


\end_layout

\begin_layout Standard
struct mutex {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
int status; 
\end_layout

\begin_layout Standard
/* we use 0 to denote that the mutex is free and 1 to denote it is locked
 by some thread.*/
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
struct fifo * waiting_queue; 
\end_layout

\begin_layout Standard
/* When the thread holding the mutex releases the mutex, it has to check
 if there is some other threads waiting in the waiting queue, if exists,
 it dequeues a waiting thread and pass the mutex to it.
 */
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
The problem is that the variable and the waiting queue are also shared among
 threads, we need to guarantee mutual exclusion of the operations on them.
 On uniprocessor systems, this can be done by simply disabling the interrupt
 when the program is manipulating these data as Algorithm 
\begin_inset LatexCommand ref
reference "alg:Getmutex-and-Releasemutex"

\end_inset

 shown.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard

\emph on
\begin_inset LatexCommand label
name "alg:Getmutex-and-Releasemutex"

\end_inset

Getmutex
\emph default
 and 
\emph on
Releasemutex
\emph default
 on uniprocessor systems
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Getmutex(mutex_t m) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
disable the interrupt;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if(m->status == 0) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
m->status=1;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
enable the interrupt;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
else 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
save the current context;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
equeue(m->waiting_queue, thread_self);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
enable the interrupt;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard
Releasemutex(mutex_t m) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
disable the interrupt;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if (m->waiting_queue == EMPTY)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
m->status=0;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
else thread = dequeue(m->waiting_queue);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
enable the interrupt;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
wakeup(thread);
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
However, this approach does not work properly on SMP systems, because although
 interrupts are disabled on the local CPU, other CPUs can still operate
 on the mutex, and there is no way to disable interrupts on all CPUs globally.
 The traditional way to solve this problem is to use a spin lock.
 With spin locks, the thread first obtains the lock, then it manipulates
 the mutex, and after that it releases the spin lock so that other threads
 can proceed.
 When the mutex is being released, the thread holding the mutex first spins
 on the mutex data structure, then if there are some other threads waiting
 in the waiting queue, then it dequeues one waiting thread, hands over the
 mutex to that thread then releases the spin lock and wakes the thread up.
 If there is no thread waiting, it resets the mutex to be free and releases
 the spin lock.
 With this mechanism, we can just use a simple FIFO queue as the waiting
 queue, because the entire 
\emph on
Getmutex
\emph default
 and 
\emph on
Releasemutex
\emph default
 are protected by a spin lock, there is no need to use a thread safe FIFO
 queue.
 Besides that, this implementation also avoids another problem: the 
\emph on
lost-wake-up 
\emph default
problem, which is a common problem in thread scheduling.
 In the next section, we will give a detailed description of it.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Lock-based 
\emph on
Getmutex
\emph default
 and 
\emph on
Releasemutex
\emph default
 on SMP systems
\end_layout

\end_inset


\end_layout

\begin_layout Standard
struct mutex_t {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
int spinlock;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
struct fifo waiting_queue;
\end_layout

\begin_layout Standard
}
\newline

\end_layout

\begin_layout Standard
Getmutex(mutex_t m) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
getSpinlock(m->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if(m->status == 0) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
m->status=1;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(m->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
else 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
save the cuurent context;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
equeue(m->waiting_queue, thread_self);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(m->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread;
\end_layout

\begin_layout Standard
}
\newline

\end_layout

\begin_layout Standard
Releasemutex(mutex_t m) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
getSpinlock(m->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if (m->waiting_queue == EMPTY)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
m->status=0;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
else thread = dequeue(m->waiting_queue);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(m->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
wakeup(thread);
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\newpage

\end_layout

\begin_layout Subsection
Lock-free mutex
\end_layout

\begin_layout Standard
Beside the lock-based approach, we can also apply the lock-free technique
 to implement the mutex.
 The problems are how to update the status of the mutex and manipulate the
 waiting queue concurrently in a lock-free manner.
 To solve these problems, we use 
\emph on
Test_and_Set 
\emph default
or
\emph on
 Swap
\emph default
 to update the status of the mutex atomically, and a lock-free FIFO queue
 is used as the waiting queue.
 Here are the details: when a thread tries to obtain the mutex, it uses
 
\emph on
Test_and_Set
\emph default
 or 
\emph on
Swap 
\emph default
to check the status variable of the mutex, and if it gets the mutex successfully
, then it continues, otherwise it saves the current context and put itself
 into the waiting queue.
 When the thread holding the mutex releases the resource, it first check
 whether there are some threads waiting in the waiting queue, if so, then
 it wakes up the first waiting thread and passes the mutex directly to it
 instead of releasing the mutex.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Structure for the lock-free mutex
\end_layout

\end_inset


\end_layout

\begin_layout Standard
struct mutex_t {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
int status;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
struct fifo waiting_queue;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "alg:The-lost-wake-up-problem"

\end_inset

The lost-wake-up problem
\end_layout

\end_inset


\end_layout

\begin_layout Standard
L1\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
Getmutex(mutex_t m) {
\end_layout

\begin_layout Standard
L2\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(TestAndSet(&m->status))
\end_layout

\begin_layout Standard
L3\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Get the mutex successfully, continue running.
 /*
\end_layout

\begin_layout Standard
L4\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
L5\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
L6\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* The mutex has been locked, we should wait in the waiting queue /*
\end_layout

\begin_layout Standard
L7\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
save the context;
\end_layout

\begin_layout Standard
L8\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
enqueue(thread_self, m->waiting_queue);
\end_layout

\begin_layout Standard
L9\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
L10\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}
\newline

\end_layout

\begin_layout Standard
L11\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
Releasemutex(mutex_t m) {
\end_layout

\begin_layout Standard
L12\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
tmp_thread = dequeue(m->waiting_queue);
\end_layout

\begin_layout Standard
L13\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(tmp_thread == NULL)
\end_layout

\begin_layout Standard
L14\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* the waiting queue is empty */
\end_layout

\begin_layout Standard
L15\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
m->status = 0;
\end_layout

\begin_layout Standard
L16\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
L17\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wakeup(tmp_thread);
\end_layout

\begin_layout Standard
L18\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
L19\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
However, the mechanism in Algorithm 
\begin_inset LatexCommand ref
reference "alg:The-lost-wake-up-problem"

\end_inset

 has a potential race condition.
 Suppose that a thread A is holding the mutex and it is trying release the
 mutex.
 If at the time that A has completed L13 but has not reached L15, another
 thread B tries to acquire the mutex.
 Since the mutex has not been released, B will insert itself into the waiting
 queue.
 However, A is not aware of that, hence it will just release the mutex by
 setting its 
\emph on
status
\emph default
 field to 0.
 But the thread A will not check the waiting queue to try to wake B up.
 This problem is called the 
\emph on
lost-wake-up
\emph default
 problem.
 It is described in 
\begin_inset LatexCommand cite
key "31"

\end_inset

.
\end_layout

\begin_layout Standard
To solve this problem, we add a counter to the mutex to denote the number
 of threads that are trying to obtain the mutex.
 When a thread tries to obtain the mutex, it first increments the counter
 by one with 
\emph on
Fetch_And_Add
\emph default
, then it uses 
\emph on
Swap
\emph default
 to change the status of the mutex.
 If successful, it decrements the counter by one, otherwise it saves the
 current context and inserts itself into the waiting queue.
 When the thread holding the mutex is releasing it, it first check if the
 counter is zero or not.
 If it is zero, then it resets the status to one, and the whole process
 is done with 
\emph on
CAS2
\emph default
 atomically.
 If the counter is not zero or 
\emph on
CAS2
\emph default
 fails to update the status, that means there are some threads trying to
 obtain the mutex, so the thread dequeues a waiting thread from the waiting
 queue, if it fails to obtain a waiting thread from the waiting queue, then
 it means that the waiting thread is in the process of en queuing itself
 into the queue.
 In this case, since we know that there will definitely be a thread waiting
 in the waiting queue, we can use a loop to check whether the thread is
 already in the queue, the loop terminates when the thread releasing the
 mutex fetches a waiting thread successfully.
 
\end_layout

\begin_layout Standard
Another potential race condition on the lock-free approach is that when
 a thread just enqueued itself into the waiting queue, before it switches
 the context, another thread may wake it up and one of the schedulers may
 start to run it immediately.
 In this case we have the same thread being run by two kernel threads at
 the time.
 The problem is that the stack of the thread is unique, hence it is shared
 by the two running instance, and this may cause stack corruption.
 This problem does not only happen to our lock-free mutex, but also to all
 other lock-free or wait-free constructs we implemented, and even the SMASH
 scheduler has this problem.
 To solve it, we use Debattista' approach
\begin_inset LatexCommand cite
key "16"

\end_inset

.
 Before enqueuing a thread to the waiting queue, we first jump to the extra
 stack offered by the SMASH scheduler, then the enqueue operation is performed.
 At this time, even if the thread is run immediately by another scheduler,
 there is no race condition any more, since we are not using its stack.
 
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Data structure of Lock free Mutex
\end_layout

\end_inset


\end_layout

\begin_layout Standard
L1\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
struct lockfree_mutex {
\end_layout

\begin_layout Standard
L2\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
int lock;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* This variable is used to denote the status of the mutex.*/
\end_layout

\begin_layout Standard
L3\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
int counter;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* This is a counter to record the number of threads trying 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
to obtain the mutex.
 */
\end_layout

\begin_layout Standard
L4\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
struct fifo waiting_queue; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* This is the waiting queue */
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard

\emph on
GetMutex
\emph default
 function for lock-free mutex
\end_layout

\end_inset


\end_layout

\begin_layout Standard
L5\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
FetchAndAdd(&mutex->counter,1);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Atomically increment the counter by one to deonte that the thread 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
is trying to obtain the mutex.
 */
\end_layout

\begin_layout Standard
L6\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(Swap(&mutex->lock,LOCKED))
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Got the mutex successfully, hence decrement the counter by one 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
since it has already got the mutex.
 */
\end_layout

\begin_layout Standard
L7\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
FetchAndAdd(&mutex->counter,-1);
\end_layout

\begin_layout Standard
L8\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Failed to obtain the mutex, hence save the current context 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
and wait in the waiting queue.
 */
\end_layout

\begin_layout Standard
L9\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
enqueue(thread_self,mutex->waiting_queue);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Switch to the next runnable thread */
\end_layout

\begin_layout Standard
L10\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread;
\end_layout

\begin_layout Standard
L11\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard

\emph on
ReleaseMutex
\emph default
 function for lock free mutex
\end_layout

\end_inset


\end_layout

\begin_layout Standard
L12\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
counter = mutex->counter;
\end_layout

\begin_layout Standard
L13\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(counter == 0)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* At this time, there is no thread trying to obtain the mutex 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
and there is no one waiting in the queue.
 Hence, we try to 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
release the mutex */
\end_layout

\begin_layout Standard
L14\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(!CAS2(<&mutex->lock,&mutex->counter>,<0,0>,<1,0>)) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Failed to release the mutex.
 There is only one possible reason: 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
the counter has been changed, i.e.
 now some threads are trying 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
to obtain the mutex.
 They may be in the process of entering 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
the waiting queue or in the queue already, hence we use a loop 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
to dequeue one waiting thread from the waiting queue.
 */
\end_layout

\begin_layout Standard
L15\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
do {
\end_layout

\begin_layout Standard
L16\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread = dequeue(mutex->waiting_queue);
\end_layout

\begin_layout Standard
L17\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}while(thread == NULL);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Decrement the counter by one */ 
\end_layout

\begin_layout Standard
L18\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
FetchAndAdd(&mutex->counter, -1);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Insert the waiting thread into the run queue.
 */
\end_layout

\begin_layout Standard
L19\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
enqueue(thread,run_queue);
\end_layout

\begin_layout Standard
L20\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard

\newpage

\end_layout

\begin_layout Subsubsection
Correctness analysis
\end_layout

\begin_layout Standard
In this section, we will give reason about the correctness of the lock-free
 mutex, however, we will not give a formal proof for it, since it is beyond
 of the scope of this project.
 A correct concurrent program has to satisfy two properties: the safety
 property and the liveness property.
 
\end_layout

\begin_layout Standard
We divide the process of obtaining a mutex into the following states: MUTEX-GET-
0, MUTEX-GET-1, MUTEX-GET-2, MUTEX-GET-3, MUTEX-GET-4, MUTEX-GET-5 and divide
 the process of releasing a mutex into the set of states: MUTEX-REL-0, MUTEX-REL
-1, MUTEX-REL-2, MUTEX-REL-3, MUTEX-REL-4, The bad combinations of states
 are: 
\end_layout

\begin_layout Enumerate
More than one thread is in MUTEX-GET-2, which means that more than one thread
 is in the critical section which should have been protected by the mutex,
 in other words, the mutual exclusion is not satisfied.
 
\end_layout

\begin_layout Enumerate
There is at least one thread is in MUTEX-REL-1, i.e.
 they are waiting in the waiting queue but the thread holding the mutex
 is in MUTEX-GET-1, i.e.
 it has released the mutex.
 In this case, we have the 
\emph on
lost-wake-up
\emph default
 problem.
 
\end_layout

\begin_layout Standard
Mutual exclusion is guaranteed since we use an atomic 
\emph on
Swap
\emph default
 at L6 to protect the critical section, so at any time only one thread can
 obtain the lock, and others have to wait for the lock to be freed.
 The 
\emph on
lost-wake-up
\emph default
 problem can be solved by the loop between MUTEX-REL-2 and MUTEX-REL-3,
 because if the thread holding the mutex releases it successfully, that
 means either there is no thread trying to obtain the mutex at all or they
 are still in MUTEX-GET-0, hence one of them is guaranteed to get the mutex.
 On the other hand, if releasing fails, that means the counter is not zero
 which implies that there exists a thread trying to obtain the mutex, in
 this case we use the loop to guarantee one of the waiting threads or the
 threads that is in its process of waiting is woken up.
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
State graph for the process of obtaining a mutex
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename mutex_get.eps

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
State graph for the process of releasing a mutex
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename mutex_rel.eps

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\newpage

\end_layout

\begin_layout Section
Semaphores
\end_layout

\begin_layout Standard
In this chapter, we will discuss implementations of semaphores for SMASH.
 Although semaphores usually are considered to be a generalization of mutexes,
 the implementations are different for efficiency reasons.
 In fact, the need for a user level semaphore on SMASH is not as important
 as that of the user-level mutex, because SMASH only creates as many kernel
 threads as the number of CPUs we have.
 Hence for systems with a small number of CPUs, for example a dual core
 or quad core machine, if the semaphore is initialized to be more than 2
 or 4 correspondingly, then there will be no contention at all, but for
 a system with a large number of CPUs, we believe that such implementations
 will still benefit the entire system.
\end_layout

\begin_layout Subsection
APIs of user-level semaphores
\end_layout

\begin_layout Subsubsection*
Semaphore initialization
\end_layout

\begin_layout Standard
This function is used to initialize a given semaphore.
 It sets the counter to the given number and creates a empty waiting queue.
 The function is not thread safe.
\end_layout

\begin_layout Subsubsection*
Semaphore wait
\end_layout

\begin_layout Standard
This function is used to perform the 
\emph on
wait 
\emph default
function.
 It decrements the counter by 1.
 If the result is negative, then the calling thread has to wait in the waiting
 queue.
\end_layout

\begin_layout Subsubsection*
Semaphore signal
\end_layout

\begin_layout Standard
This function is used to perform the 
\emph on
signal 
\emph default
function.
 It increments the counter by 1, then it checks whether there is any thread
 waiting in the waiting queue.
 If so, it wakes one up.
 
\end_layout

\begin_layout Subsection
Lock-based implementation for semaphores
\end_layout

\begin_layout Standard
The semaphore can be considered to be a generalization of mutex.
 A semaphore contains a counter.
 On initialization, this counter is set to some initial number N, each wait
 operation decrements the counter until it reaches zero, after which 
\emph on
wait
\emph default
 operations will cause the calling thread to be blocked in the waiting queue.
 A thread releases the semaphore by calling the function 
\emph on
signal
\emph default
, which will increment the counter by one if no other threads are waiting
 in the waiting queue, or wake up a waiting thread.
 Here is the general data structure of a semaphore.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
General data structure of a semaphore
\end_layout

\end_inset


\end_layout

\begin_layout Standard
struct sem_t {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
int counter;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
struct fifo waiting_queue;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
To implement semaphores, we have some similar issue to those of mutex, the
 counter has to be updated atomically and the waiting queue has to be thread-saf
e.
 On uniprocessor systems, we can still simply disable interrupts to guarantee
 the atomicity of these operations, and on SMP systems, we can use a spin
 lock to protect the critical sections.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Lock-based semaphore implementation on SMP systems
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Wait(sem_t s) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
getSpinlock(s->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if(s->counter <= 0)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
save the current context;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
enqueue(thread_self, s->waiting_queue);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(s->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
switch to the next runnable thread;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
s->counter- -;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(s->spinlock);
\end_layout

\begin_layout Standard
}
\newline

\end_layout

\begin_layout Standard
Signal(sem_t s) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
getSpinlock(s->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if(s->counter > 0)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* The resource is still available, no one is in the waiting queue */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
s->counter++;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(s->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
else 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* The resource is not available, there may be some one waiting in the waiting
 queue.
 */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread = dequeue(s->waiting_queue);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(thread != NULL)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wakeup(thread);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
A Lock-free implementation
\end_layout

\begin_layout Standard
To implement the lock-free version of semaphores, we have to consider several
 issues.
 First, the counter has to be updated atomically, and since the counter
 can take any integer value, we can not use 
\emph on
Test_and_Set
\emph default
 to update it, instead, we have to use other atomic instructions to modify
 the counter.
 In addition, we still use a lock free FIFO queue as the waiting queue.
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard

\emph on
wait
\emph default
 function of the lock-free semaphore
\end_layout

\end_inset


\end_layout

\begin_layout Standard
wait(sem_t s) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* we may also use FetchAndAdd here, but I suspect that the following code
 can improve the latency.
 */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
do {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
counter = s->counter;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}while(!cas(&s->counter,counter,counter-1));
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(counter < 0)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* The resouce is not available, wait in the waiting queue */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
save the current contex;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
enqueue(thread_self, s->waiting_queue);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
switch to the next runnable thread;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* The resource is still available */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
The 
\emph on
lost-wake-up
\emph default
 problem
\end_layout

\begin_layout Standard
In the implementation of the lock-free semaphore, we also have the same
 
\emph on
lost-wake-up
\emph default
 problem as that in mutex implementation.
 One of the threads holding the semaphore may fail to dequeue a waiting
 thread from the waiting queue because at the time the thread checks the
 waiting queue, it has not yet enqueued itself into the queue.
 However, this time, the problem is harder to solve.
 Suppose that we try to solve it with the same method that we used in the
 lock-free mutex implementation.
 
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Lost-wake-up problem
\end_layout

\end_inset


\end_layout

\begin_layout Standard
L1\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
signal(sem_t s) {
\end_layout

\begin_layout Standard
L2\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(s->counter > 0)
\end_layout

\begin_layout Standard
L3\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
FetchAndAdd(&s->counter, 1);
\end_layout

\begin_layout Standard
L4\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
L5\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
do {
\end_layout

\begin_layout Standard
L6\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread = dequeue(s->waiting_queue);
\end_layout

\begin_layout Standard
L7\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(thread != NULL)
\end_layout

\begin_layout Standard
L8\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wakeup(thread);
\end_layout

\begin_layout Standard
L9\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
L10\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
while(thread == NULL);
\end_layout

\begin_layout Standard
L11\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The problem is that in this case, we may have multiple dequeuers that dequeue
 the waiting threads from the waiting queue.
 If one fails to find any threads waiting in the queue, then there are two
 possibilities: one is that the waiting thread has not yet inserted itself
 in the queue, or maybe the waiting thread has been woken up by another
 thread holding the semaphore.
 This may cause some threads loop forever trying to dequeue a waiting thread
 while actually there is no one waiting.
 
\end_layout

\begin_layout Standard
To solve this problem, we first allow the counter to take negative integer
 values.
 If the counter takes a negative value, then its modulus represents the
 number of threads waiting for the resource.
 When a thread is trying to release the semaphore, it uses a loop in which
 it first checks whether the counter is negative or not.
 If the counter is non-negative, then it increments the counter by 1.
 Otherwise the counter is negative, then there exists a thread waiting in
 the queue.
 Hence the thread releasing the semaphore tries to dequeue a waiting thread
 from the waiting queue.
 If it fails to get a waiting thread, then it re-reads the counter and execute
 the loop again.
 The pseudo code is shown in Algorithm 
\begin_inset LatexCommand ref
reference "alg:Incomplete-solution-to"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement !h
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "alg:Incomplete-solution-to"

\end_inset

Incomplete solution to 
\emph on
lost-wake-up
\emph default
 problem
\end_layout

\end_inset


\end_layout

\begin_layout Standard
L1\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
signal(sem_t s) {
\end_layout

\begin_layout Standard
L2\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
do {
\end_layout

\begin_layout Standard
L3\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(s->counter < 0 )
\end_layout

\begin_layout Standard
L4\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
tmp_thread = dequeue(s->waiting_queue);
\end_layout

\begin_layout Standard
L5\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(tmp_thread == NULL)
\end_layout

\begin_layout Standard
L6\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
continue;
\end_layout

\begin_layout Standard
L7\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
L8\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
FetchAndAdd(s->counter, 1);
\end_layout

\begin_layout Standard
L9\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wakeup(tmp_thread);
\end_layout

\begin_layout Standard
L10\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
L11\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
L12\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
FetchAndAdd(s->counter,1);
\end_layout

\begin_layout Standard
L13\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
L14\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}while(true);
\end_layout

\begin_layout Standard
L15\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
However, this does not solve the problem completely, as there is another
 race condition.
 Suppose a thread A holding the semaphore is trying to release the resource,
 and it just finishes L3 with the counter greater than zero.
 The next instruction to be run should be L12, but before the counter is
 incremented, suppose the resource is used up and some threads have enqueued
 themselves into the waiting queue.
 Then at least one of the waiting thread will not be woken up, i.e.
 we again have the 
\emph on
lost-wake-up
\emph default
 problem.
 To solve this problem, we have to guarantee that the process of testing
 the counter and updating it if it is not negative should be atomic.
 Hence, we use an outer do-while loop surrounding the do-while loop in the
 above pseudo code and use 
\emph on
Compare_And_Swap
\emph default
 to update the counter.
 
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Proper implementation for 
\emph on
signal
\emph default
 on the lock-free semaphore
\end_layout

\end_inset


\end_layout

\begin_layout Standard
L1\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
signal(sem_t s) {
\end_layout

\begin_layout Standard
L2\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
do{
\end_layout

\begin_layout Standard
L3\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
old = s->counter
\end_layout

\begin_layout Standard
L4\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
do {
\end_layout

\begin_layout Standard
L5\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if( s->counter< 0 )
\end_layout

\begin_layout Standard
L6\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
tmp_thread = dequeue(s->waiting_queue);
\end_layout

\begin_layout Standard
L7\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(tmp_thread == NULL)
\end_layout

\begin_layout Standard
L8\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
continue;
\end_layout

\begin_layout Standard
L9\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
L10\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
FetchAndAdd(&s->counter, 1);
\end_layout

\begin_layout Standard
L11\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wakeup(tmp_thread);
\end_layout

\begin_layout Standard
L12\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
L13\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
L14\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
break;
\end_layout

\begin_layout Standard
L15\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}while(true);
\end_layout

\begin_layout Standard
L16\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}while(!CAS(&s->counter,old,old+1))
\end_layout

\begin_layout Standard
L17\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Correctness analysis
\end_layout

\begin_layout Standard
Lock-free semaphores are more complicated than lock-free mutexes.
 We divide the process of waiting on a semaphore into five states: SEM-WAIT-0,
 SEM-WAIT-1,SEM-WAIT-2, SEM-WAIT-3, SEM-WAIT-4, and divide the process of
 signaling a semaphore into six states: SEM-SIG-0, SEM-SIG-1, SEM-SIG-2,
 SEM-SIG-3, SEM-SIG-4, SEM-SIG-5.
 To check the safety property, we first identify the bad combinations of
 states.
 Suppose the counter of the semaphore was initialized to be N.
 The first bad combination is that there are more than N threads in SEM-WAIT-4,
 i.e.
 there are more than N threads accessing the resource protected by the semaphore.
 The second bad combination is the case in which the counter of the semaphore
 is greater than or equal to zero, but there still exist threads waiting
 in the waiting queue, i.e.
 we have the 
\emph on
lost-wake-up
\emph default
 problem.
 The third one is that a thread is in the state SEM-REL-3 but the counter
 is non-negative.
 In this case the thread will loop forever trying to wake someone up but
 there is actually no one in the waiting queue.
\end_layout

\begin_layout Standard
The first case is not possible.
 Because if the counter is less than zero, then a thread A trying to obtain
 the semaphore has to wait in the waiting queue, even another thread B holding
 the semaphore released the resource just after the time thread A checked
 the counter.
 In this case, A has to insert itself into the waiting queue and wait for
 other thread to wake it up.
 The second case will not happen because for each thread waits in the waiting
 queue, they have already decremented the counter so that it is negative,
 and the counter will not be incremented unless one of the waiting threads
 is woken up successfully.
 Even in the case that the counter becomes negative when a thread holding
 the resource is in the state SEM-REL-1, it will not be able to update the
 counter successfully since the counter is updated with 
\emph on
Compare_And_Swap
\emph default
, and consequently it will go back to SEM-REL-0.
 The last situation is also impossible because once a thread holding the
 resource fails to dequeue a waiting thread from the waiting queue, it rechecks
 the counter.
 If the counter is not negative any more, then the execution goes back to
 SEM-REL-0.
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
State graph for the 
\emph on
wait
\emph default
 function on the lock-free semaphore
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename sem_wait.eps
	scale 80

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
State graph of the 
\emph on
signal
\emph default
 function on the lock-free semaphore
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename sem_sig.eps
	scale 70

\end_inset


\end_layout

\end_inset


\newpage

\end_layout

\begin_layout Section
Message queues
\end_layout

\begin_layout Standard
In this chapter, we will discuss implementations of message queues.
 The message queues we implemented are unbounded, multiple sender, single
 dequeuer queues.
 Unboundedness means that these queues are potentially capable of storing
 infinitely many messages, since the only limit is the memory space.
 Also there can be more than one sender that send messages to the queue,
 but there is only one receiver.
 If the receiver tries to retrieve a message from a empty queue, it blocks
 until a sender wakes it up.
 
\end_layout

\begin_layout Subsection
APIs of message queues
\end_layout

\begin_layout Subsubsection*
Message queue initialization
\end_layout

\begin_layout Standard
This function initializes a message queue.
 It creates an empty FIFO queue to store messages and sets the other field
 in the message queue to the initial values.
\end_layout

\begin_layout Subsubsection*
Send message
\end_layout

\begin_layout Standard
Given the memory address of a message, this function creates a new node
 to store the message and enqueues the node to the given message queue,
 if the receiver is waiting for the message, it will wake the waiting thread
 up.
\end_layout

\begin_layout Subsubsection*
Fetch message
\end_layout

\begin_layout Standard
The receiver of a message queue calls this function to dequeue a message
 from the message queue, if the queue is empty, then the receiver will block
 until a message is available.
 This function returns the address where the message is stored in the memory,
 and it automatically destroys the dequeued node structure by using the
 function 
\emph on
free
\emph default
.
\end_layout

\begin_layout Subsection
Lock-based implementation
\end_layout

\begin_layout Standard
The lock-based approach is quite simple, as we just use a spin lock to protect
 the queue.
 Note that it is not enough to just protect the FIFO queue which is used
 to store the message, because it is possible that we encounter a situation
 where a sender just inserts a message into an empty queue and find no one
 is waiting, but the real case is that the receiving thread is in the process
 of saving its context and making itself wait on the message queue because
 the queue was empty at the time it was checked.
 In this case, we again suffer from the 
\emph on
lost-wake-up
\emph default
 problem.
 Hence, a spin lock is used to protect the entire function calls of 
\emph on
Send_message
\emph default
 and 
\emph on
Fetch_message
\emph default
.
 In this way, it is guaranteed that when the receiver is fetching the message
 and the message is empty, a sender will not be able to send the message
 until the receiver is waiting for the message.
 
\end_layout

\begin_layout Standard
Since the entire processes of sending and receiving messages are protected
 by a spin lock, we can use a simple FIFO queue as the queue storing the
 messages.
 The FIFO queue is implemented as a single linked-list with a dummy head
 node.
 Each node contain a 
\emph on
data
\emph default
 pointer pointing to the memory location where the actual message is stored
 and a 
\emph on
next 
\emph default
pointer which points to the next node in the FIFO queue.
 
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Structure for nodes of the FIFO queue
\end_layout

\end_inset


\end_layout

\begin_layout Standard
struct fifo_node {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
void * data_pointer;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
struct fifo_node * next;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset

The queue itself has two pointers: the 
\emph on
head
\emph default
 pointer pointing to the head node of the queue, and the 
\emph on
tail
\emph default
 pointer pointing to the tail node.
 Initially, both head and tail pointers point to the dummy.
 The enqueue operation appends a new node to the tail of the list and the
 dequeue operation removes the current dummy head from the queue and makes
 the next node be the new dummy head.
\end_layout

\begin_layout Standard
When a sender sends a message, it uses 
\emph on
malloc 
\emph default
to create a new node in the heap and enqueue the new node to the message
 queue.
 Then the receiver will dequeue the message and use 
\emph on
free 
\emph default
to free the space allocated to the old dummy head.
 Since nodes only store pointers to actual messages, the length of messages
 can be arbitrary.
 It is up to the application developer who uses the message queue to decide
 the detailed structures of messages.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Lock-based message queue
\end_layout

\end_inset


\end_layout

\begin_layout Standard
struct message_queue {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
int spinlock;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
struct fifo queue;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
cthread waiting_thread;
\end_layout

\begin_layout Standard
}
\newline

\end_layout

\begin_layout Standard
Send_message(message, message_queue q) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
getSpinlock(q->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
enqueue(message,q->queue);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if(q->waiting_thread != NULL)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* no thread is blocking */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
tmp_thread = q->waiting_thread;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
q->waiting_thread = NULL;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wakeup(tmp_thread);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(q->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
}
\newline

\end_layout

\begin_layout Standard
Fetch_message(message_queue q) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
getSpinlock(q->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
message = dequeue(q->queue);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if(message == NULL)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* The message queue is empty, we wait.
 */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
save the current context;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
q->waiting_thread = thread_self;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(q->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
switch to the next runnable thread;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(q->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
return message;
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Lock-free implementation
\end_layout

\begin_layout Standard
To implement the lock-free message queue, there are two issues to solve.
 The first one is that the FIFO queue has to be thread safe, the second
 one is the 
\emph on
lost-wake-up
\emph default
 problem.
 The former issue can be solved by using a lock-free FIFO queue.
 In order to solve the lost-wake-up problem, an extra field, called 
\emph on
waiting_mark, 
\emph default
is added to the message queue structure.
 When a receiver fetches a message from the queue, it first sets the mark
 to WAITING, then it performs the dequeue operation.
 If the result is NULL, then it blocks.
 Otherwise, the result is not NULL, then the function resets 
\emph on
waiting_mark 
\emph default
to NOWAITING and returns the result.
 When a sender sends a message to a message queue, it first enqueues the
 node containing the message to the queue.
 Then it uses a 
\emph on
do-while 
\emph default
loop, which ends if the value of 
\emph on
waiting_mark
\emph default
 is not WAITING, to try to wake up the receiver(if any).
 In the loop, the thread first swaps NULL into the field 
\emph on
waiting_thread
\emph default
 and if its old value is not NULL, then it wakes up the receiver and sets
 the field 
\emph on
waiting_mark 
\emph default
to NOWAITING.
 
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
The data structure of the lock-free message queue 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
struct message_queue {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
struct lockfree_fifo * queue;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
cthread * waiting_thread;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
int waiting_mark;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard

\emph on
Fetch_message
\emph default
 function of the lock-free message queue
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
Fetch_message(struct message_queue * q) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
while(true) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
queue->waiting_mark = WAITING; /* This means that the receiver is fetching
 messages */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
result = dequeue(q->queue);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(result == NULL)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* The queue is empty.
 */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
save the current context;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
q->waiting_thread = thread_self;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
switch to the next runnable thread;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
continue on wakeup
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
queue->waiting_mark = NOWAITING; /* denote that no one is waiting */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
reture result;
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard

\emph on
Send_message
\emph default
 of the lock-free message queue
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Send_message(message, struct message_queue q) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
enqueue(message, q->queue);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
do {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread = swap(&queue->waiting_thread,NULL);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(thread != NULL)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Do NOT exchange the order of the following instructions,
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
because it will lead to a potential race condition */
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
queue->waiting_mark = NOWAITING;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wakeup(thread);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
while(queue->waiting_mark == WAITING);
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Correctness
\end_layout

\begin_layout Standard
We divide the the process of sending a message into 5 states: QUEUE-SEND-1,
 QUEUE-SEND-2, QUEUE-SEND-3, QUEUE-SEND-4, QUEUE-SEND-5, and the process
 of fetching a message into 6 states: QUEUE-FETCH-1, QUEUE-FETCH-2, QUEUE-FETCH-
3, QUEUE-FETCH-4, QUEUE-FETCH-5, QUEUE-FETCH-6.
 And we produce the state diagrams for them.
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
The state diagram for sending messages
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~

\begin_inset Graphics
	filename queue_send.eps
	scale 80

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
The state diagram for fetching messages
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~

\begin_inset Graphics
	filename queue_fetch.eps
	scale 80

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
In this case, the only problem is the 
\emph on
lost-wake-up 
\emph default
problem.
 And it will not happen because before the receiver of a message queue tries
 to fetch a message from the queue, it sets the field 
\emph on
waiting_mark 
\emph default
to the value WAITING.
 And as long as the value of 
\emph on
waiting_mark
\emph default
 is still WAITING, senders will keep looping to check the field 
\emph on
waiting_thread
\emph default
.
 If its value is not NULL, which means the receiver has blocked or is in
 the process of blocking on the message queue, then one of the sender will
 reset the 
\emph on
waiting_mark 
\emph default
field to NOWAITING and then wake the receiver up.
 If the receiver gets a message successfully in the first place, then it
 will reset the 
\emph on
waiting_mark 
\emph default
to NOWAITING.
\end_layout

\begin_layout Standard

\newpage

\end_layout

\begin_layout Section
Channels
\end_layout

\begin_layout Standard
In this chapter, we implemented the CSP communication channels designed
 by Vella
\begin_inset LatexCommand cite
key "15"

\end_inset

 for KRoC.
 KRoC is an implementation of the OCCAM 2 programming language
\begin_inset LatexCommand cite
key "28"

\end_inset

.
 OCCAM is a concurrent programming language which is built on the communicating
 sequential process algebra.
 Channels here have the same semantics as those in the OCCAM 2 programming
 language.
 
\end_layout

\begin_layout Subsection
Semantics of channels
\end_layout

\begin_layout Standard
Channels are used for unbuffered synchronized communications between threads.
 A channel has two ends, the input end and the output end.
 At any time, only one thread can read input from a channel and only one
 thread can output to the channel.
 Also the communication is synchronized, which means the communication will
 not happen until the two ends are both ready, and the message is copied
 directly from the outputting thread to the inputting thread.
 That means there is no intermediate buffer between them.
 If one of the communication ends is not ready to take action, then the
 other end will block to wait for it.
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Example of channel communication
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename chan_out_wait.eps

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset

 This enforces determinism, since we know when the communication will happen
 and the source and the destination of the communication.
 
\end_layout

\begin_layout Standard
However, in some cases, we may need the communication to be non-deterministic,
 for example, a web server waiting for client requests.
 In this case, the server will not be able to know which client will send
 the request first.
 OCCAM provides 
\emph on
alternatives 
\emph default
to cater for this situation.
 
\emph on
Alternatives
\emph default
 allow an input thread wait on a set of channels for communication.
 When one of the channels is ready, the communication will happen on that
 channel.
 If none of them is ready at the time the inputting thread is trying to
 receive messages, then the inputting thread sleeps until one of the channels
 is ready.
 On the other hand, if more than one channel is ready at the same time,
 the inputting thread will pick one of them.
 In theory, the choice should be totally nondeterministic, but it is hard
 to implement efficiently, so in practice, the choice is made in a deterministic
 manner.
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Alternative of channels
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename alt.eps
	scale 90

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
APIs for channels
\end_layout

\begin_layout Subsection*
Channel input with alternative
\end_layout

\begin_layout Standard
This function is used when a thread tries to take input from an array of
 channels, and it follows the same semantics as described in the above section.
 This function can be used for simple channel communication, but it is different
 from the channel implementation provided by SMASH, since 
\emph on
alternative 
\emph default
is always enabled.
\end_layout

\begin_layout Subsection*
Channel output with alternative
\end_layout

\begin_layout Standard
This function is used when a thread tries to output on a channel.
 
\emph on
Alternative support 
\emph default
is always enabled even in the case of simple channel communications.
\end_layout

\begin_layout Subsection
Simple Channel communication
\end_layout

\begin_layout Standard
SMASH provides lock-based and wait-free implementations of channels for
 simple channel communications.
 These channels do not support alternatives.
 They are tightly integrated with SMASH, since in the thread descriptor
 structure of SMASH, there is a pointer used to pointing to the memory address
 of the message and the length of a message is also recorded in this structure.
 Messages are copied directly from one thread to the other.
 
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Data structure for wait-free channels without alternative support
\end_layout

\end_inset


\end_layout

\begin_layout Standard
struct channel {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
cthread * communicator
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Wait-free channel input
\end_layout

\end_inset


\end_layout

\begin_layout Standard
channel_in(channel chan, int n) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
save the current context
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(CAS(chan->communicator, NULL, self))
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return on wakeup
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
copy n bytes from chan->communicator->message
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
chan->communicator = NULL
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wakeup(chan->communicator)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Wait-free channel output
\end_layout

\end_inset


\end_layout

\begin_layout Standard
channel_out(channel chan, int n) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
save the current context
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if(CAS(chan->communicator,NULL self))
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
// The inputting thread has not reached the communication point yet, we
 sleep.
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return on wakeup
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
copy n bytes TO chan->communicator->message
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
chan->communicator = NULL
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wakeup(chan->communicator)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Lock-based Channels with alternative support
\end_layout

\begin_layout Standard
In this section, we implemented channel communication with alternative support
 by using spin locks.
 Our design is quite simple, the set of channels participating the communication
 are grouped together into a data structure called 
\emph on
channel set, 
\emph default
when a thread tries to input from the set of channels, it uses a spin lock
 to lock the entire set, then it checks whether there is a channel in the
 set ready for communication, i.e.
 the outputting thread is waiting on that channel, if a channel is ready,
 then the inputting thread copies the message from the channel and wakes
 up the outputting thread.
 If none of the channels is ready, then it blocks on all these channels.
\end_layout

\begin_layout Standard
When an outputting thread tries to output on a channel, it also locks the
 entire set of channels, then it check if the inputting thread is ready
 for communication, if the inputting thread is ready, then it copies the
 message to that thread and wakes it up, after which, the outputting thread
 loops over all these channels, if it finds that the inputting thread is
 also waiting on other channels, it will disable these channels by setting
 the 
\emph on
channel communicator
\emph default
 field to NULL.
 Then it wakes up the inputting thread and releases the spin lock.
 If the channel is not ready for communication, it releases the spin lock
 and blocks itself on the channel.
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Data structure for 
\emph on
channel set
\end_layout

\end_inset


\end_layout

\begin_layout Standard
struct channel_set {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
channel ** chan_array;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
int chan_num;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
int spinlock;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Lock-based channel input with alternative support
\end_layout

\end_inset


\end_layout

\begin_layout Standard
channel_in(channel_set * chan_set, void * message, int length) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
getSpinlock(chan_set->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
save the current context;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
for(count = 0; count < chan_set->chan_num; count++)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(chan_set->chan_array[count]->communicator != NULL)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
copy message from the channel;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
chan_set->chan_array[count]->communicator = NULL;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wake up the communicator;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(chan_set->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
for(count = 0; count < chan_set->chan_num; count++)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
chan_set->chan_array[count]->communicator = thread_self;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(chan_set->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Lock-based channel output with alternative support
\end_layout

\end_inset


\end_layout

\begin_layout Standard
channel_out(channel_set * chan_set, int index, void * message, int length)
 {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
getSpinlock(chan_set->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
save the current context;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
input_thread = chan_set->chan_array[index]->communicator; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if(input_thread != NULL)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
copy message to the channel;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(count = 0; count < chan_set->chan_num; count++)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(chan_set->chan_array[count]->communicator == input_thread)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
chan_set_>chan_array[count]->communicator = NULL;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wake up input_thread;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(chan_set->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
chan_set->chan_array[index]->communicator = thread_self;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
releaseSpinlock(chan_set->spinlock);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread;
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Wait-free Channels with alternative support
\end_layout

\begin_layout Standard
Vella designed a wait-free channel for KRoC in his PhD thesis
\begin_inset LatexCommand cite
key "15"

\end_inset

, and in this project, we ported it to SMASH.
 The algorithm is array-based, which means that the number of channels that
 participate in the alternative is fixed and is known before the communication
 starts.
 In the design, the only atomic instruction used is 
\emph on
Swap.

\emph default
 When a thread outputs to a channel, it first saves its current context,
 then uses swap instruction to get the current value of the channel communicator
 and insert itself to the 
\emph on
communicator
\emph default
 field.
 Then it checks if the value it got is NULL or not.
 If the value is NULL, then it means that at the time of the execution of
 the 
\emph on
swap
\emph default
 instruction, the inputting thread had not reached the communication point
 yet, so the outputting thread goes to sleep.
 If the channel communicator was not NULL, i.e.
 the inputting thread had insert itself to the 
\emph on
communicator
\emph default
 field of the channel, the outputting thread then uses 
\emph on
swap
\emph default
 again to read the old value of the field 
\emph on
pointer 
\emph default
in the inputting thread structure and sets its new value to READY atomically,
 then it checks the old value.
 If the old value was ENABLING or READY, then it goes to sleep, while if
 the old value was WAITING, which means the inputting thread is sleeping
 or is in the process of sleeping, so it should be woken up again.
 If the old value is none of the above values, it means that the alternative
 is disabled, i.e.
 the communication is just a simple channel communication, then the mechanism
 of simple channel communications is applied.
 
\end_layout

\begin_layout Standard
When a thread inputs from a group of channels, the entire process is divided
 into three phases: 
\end_layout

\begin_layout Enumerate
The enabling phase,
\end_layout

\begin_layout Enumerate
The alternative waiting phase, 
\end_layout

\begin_layout Enumerate
The disabling phase.
\end_layout

\begin_layout Standard
In the enabling phase, the inputting thread first sets the 
\emph on
pointer 
\emph default
field in its thread structure to ENABLING, then it loops over the set of
 channels.
 For each channel, it uses 
\emph on
swap 
\emph default
to retreive the old value of the channel communicator and insert itself
 to the 
\emph on
communicator
\emph default
 field, then it checks whether the old value is NULL or not.
 If the old value was not NULL, then it sets its 
\emph on
pointer
\emph default
 field to READY and resets the channel communicator to its old value.
 This process is done for every channel participating in the communication.
 One thing to note is that in this phase, the inputting thread does not
 need to save its context.
\end_layout

\begin_layout Standard
The second phase is the alternative phase, in this phase, the inputting
 thread first sets its 
\emph on
temp 
\emph default
field in the thread structure to NULL and saves its current context, then
 it uses 
\emph on
swap 
\emph default
to get the old value of the 
\emph on
pointer
\emph default
 field and sets its new value to WAITING.
 After that, it checks the old value, and if the value was ENABLING, we
 then go to the disabling phase.
 If the value was READY, then it swaps
\emph on
 
\emph default
the value READY back to the 
\emph on
pointer 
\emph default
field and gets the previous value atomically.
 If the newly retrieved value is also READY, that means the 
\emph on
pointer
\emph default
 field has been changed by the outputting thread during L5, so we have to
 go to sleep since the outputting thread will wake us up anyway.
 If the value retrieved at L6 is not READY, then we should go to the third
 phase.
 
\end_layout

\begin_layout Standard
The last phase is the disabling phase.
 During this phase, the inputting thread chooses one of the ready channels
 to complete the communication and disables all other channels.
 It is guaranteed that if a inputting thread enters this phase, then there
 exists a channel that is ready for the communication.
 In this phase, the inputting thread loops against the channel array to
 swap the value NULL to the channel communicator field one by one and checks
 the swapped value.
 If the value is the memory address of the inputting thread's thread structure,
 then it does nothing.
 If the swapped value is some other value, i.e.
 it is the address of an outputting thread, and the 
\emph on
temp 
\emph default
field of the inputting thread is still NULL, then we set the 
\emph on
temp
\emph default
 field to that value to denote that the corresponding channel is chosen
 for communication.
 If the value of 
\emph on
temp 
\emph default
is not NULL, which means a channel is already chosen, then we put the outputting
 thread back into the channel communicator field.
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Enabling phase of channel input
\end_layout

\end_inset


\end_layout

\begin_layout Standard
channel_enable(channel chan_array, int array_size) {
\end_layout

\begin_layout Standard
L1\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/*Enabling alternative support.*/
\end_layout

\begin_layout Standard
L2\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread_self->pointer = ENABLING
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Loop against channel array to check whether any channel is ready.
 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
i.e.
 some outputting threads have already been waiting on the 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
corresponding channels */
\end_layout

\begin_layout Standard
L3\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(count = 0; count < array_size; count ++)
\end_layout

\begin_layout Standard
L4\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
temp_thread = swap(chan_array[count]->communicator, 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread_self)
\end_layout

\begin_layout Standard
L5\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(temp_thread != NULL)
\end_layout

\begin_layout Standard
L6\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* This channel is ready */
\end_layout

\begin_layout Standard
L7\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread_self->pointer = READY
\end_layout

\begin_layout Standard
L8\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
chan_array[count]->communicator = temp_thread
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Alternative waiting phase for channel input
\end_layout

\end_inset


\end_layout

\begin_layout Standard
alt_wait(channel chan_array, int array_size) {
\end_layout

\begin_layout Standard
L1\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* Start alternative wait phase */
\end_layout

\begin_layout Standard
L2\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread_self->temp = NULL
\end_layout

\begin_layout Standard
L3\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
save the current context
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* put the value WAITING to thread_self->pointer 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
and retrieve its previous value atomically by using swap */
\end_layout

\begin_layout Standard
L4\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
temp = swap(thread_self->pointer, WAITING)
\end_layout

\begin_layout Standard
L5\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(temp == READY)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* one of the channels is ready, change the value back to READY */
\end_layout

\begin_layout Standard
L6\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
temp = swap(thread_self->pointer, READY)
\end_layout

\begin_layout Standard
L7\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(temp == READY)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* some outputting thread just changed the value 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
and try to wake us up while we are not sleeping, 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
so release the CPU */
\end_layout

\begin_layout Standard
L8\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread
\end_layout

\begin_layout Standard
L9\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return on wake up
\end_layout

\begin_layout Standard
L10\InsetSpace ~
\InsetSpace ~
else if (temp == ENABLING)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* No channel is ready yet */
\end_layout

\begin_layout Standard
L11\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread
\end_layout

\begin_layout Standard
L12\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return on wake up
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Disabling phase for channel input
\end_layout

\end_inset


\end_layout

\begin_layout Standard
channel_disable(channel chan_array, int array_size) {
\end_layout

\begin_layout Standard
/* Disabling all channels and choose one channel from the ready ones to
 finish the communication */
\end_layout

\begin_layout Standard
L1\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(count = 0; count < array_size; count++)
\end_layout

\begin_layout Standard
L2\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
temp_thread = swap(chan_array[count]->communicator, NULL)
\end_layout

\begin_layout Standard
L3\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(temp_thread == thread_self)
\end_layout

\begin_layout Standard
L4\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
continue
\end_layout

\begin_layout Standard
L5\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
L6\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
if(thread_self->temp == NULL)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
/* This channel is ready and no channel has been selected, 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
we can choose this one */
\end_layout

\begin_layout Standard
L7\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread_self->temp = temp_thread
\end_layout

\begin_layout Standard
L8\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
L9\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
chan_array[count]->communicator = temp_thread
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
 channel input of the wait-free channel
\end_layout

\end_inset


\end_layout

\begin_layout Standard
channel_in_alt(channel chan_array, int array_size, void * message, int length)
\end_layout

\begin_layout Standard
{
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
channel_enable(chan_array,array_size)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
alt_wait(chan_array,array_size)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
channel_disable(chan_array,array_size)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
copy message from thread_self->temp
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
wake up thread_self->temp
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Channel out for wait-free channels
\end_layout

\end_inset


\end_layout

\begin_layout Standard
channel_out(channel chan, void * message, int length) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
save the current context
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
temp_thread = swap(chan->communicator, thread_self)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
if(temp_thread == NULL)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return on wake up
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
else
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
temp_pointer = swap(temp_thread->pointer,READY)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
switch(temp_pointer) {
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
case ENABLING:
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
case READY:
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return on wake up
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
case WAITING:
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
wake up temp_thread
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
schedule the next runnable thread
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return on wake up
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
default:
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
copy message to temp_thread->pointer
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
return
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Correctness
\end_layout

\begin_layout Standard
The correctness of this wait-free channel has been proved in 
\begin_inset LatexCommand cite
key "11"

\end_inset

, so we are not going to give an analysis.
 Instead, we just give state diagrams for the enabling phase and the alternative
 waiting phase.
 The disabling phase is very simple so we do not give a diagram for it.
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Enabling phase of channel input
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~

\begin_inset Graphics
	filename chan_in_enabling.eps
	scale 80

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Alternative waiting phase of channel input
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename chan_in_alt.eps
	scale 80

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
In this chapter, we discussed the designs and implementations for user-level
 mutexes, semaphores, message queues and the CSP channels.
 As we can see, the lock-based designs are all relatively simple and the
 correctness is easy to check.
 In contrast, The lock-free implementations are more complicated, and to
 check the correctness, simple analysis is not enough.
 Instead, rigorous mathematical proofs have to be done to guarantee the
 correctness.
 In the next chapter, we are going to present some benchmarks about these
 constructs and give some analyze the performance.
\end_layout

\begin_layout Chapter
Performance
\end_layout

\begin_layout Standard
In this chapter, we will give a performance analysis for all inter-thread
 communication constructs introduced in this dissertation.
 For each kind of construct, both the lock-based and lock-free implementation
 are used.
 The machine we used is a laptop equipped with a Intel Core2 Duo 1.83Ghz
 CPU with 4Mb L2 cache, 2Gb memory.
 The operating system is Debian GNU/Linux unstable with Linux kernel version
 2.6.24.
 The compiler is GCC 4.3.
 When measuring these benchmarks, we try to run as few programs as possible,
 the largest program running being the X-window system.
\end_layout

\begin_layout Section
Benchmarks for mutex
\end_layout

\begin_layout Standard
Originally, SMASH did not implement the user-level mutex, so when a mutex
 was needed, one had to user either pthread's mutex or a spin lock directly.
 Either way, if the mutex or spin lock is under contention, not only does
 the user-level thread block, but so does the underlying kernel, and consequentl
y, no other user-level threads can run on that kernel thread.
 In the worst case, all kernel threads except the one on which the user-level
 thread holding the mutex will be blocked.
 This will slow down the entire system.
 
\end_layout

\begin_layout Standard
We created six identical independent tasks, each of which contains nothing
 but a critical section protected by a mutex.
 In the critical section, a thread loops to increment a counter which is
 not shared.
 For each critical section, we create ten user-level threads working on
 it.
 The program loops for a number which is defined by GRANULARITY.
 We used a pthread mutex and our lock-free mutex to analyze the performance.
 It is desirable that the choice of different implementations of user-level
 mutexes will not make a significant difference since we are measuring the
 performance of the entire system, not that of mutexes.
 
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
The benchmark of the system using lockfree user-level mutex
\end_layout

\end_inset


\end_layout

\begin_layout Standard
#define TASK_NUM 6 
\end_layout

\begin_layout Standard
#define THREAD_PER_TASK 10 
\end_layout

\begin_layout Standard
#define STEP 500000 
\end_layout

\begin_layout Standard
int GRANULARITY = STEP; 
\end_layout

\begin_layout Standard
cmutex_t m[TASK_NUM]; 
\end_layout

\begin_layout Standard
long task[TASK_NUM]; 
\end_layout

\begin_layout Standard
void test(cthread * ct,int task_num) { 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
int count,n=0; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
GetMutex(&m[task_num]); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(count=0;count < GRANULARITY;count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
n++; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
ReleaseMutex(&m[task_num]); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
cthread_stop(); 
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard
void cthread_main() { 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
int count,i=0,thread_num = THREAD_PER_TASK * TASK_NUM; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
int thread_count = 0; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
struct timeval t1,t2; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
cthread * c[TASK_NUM][THREAD_PER_TASK]; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(count=0;count<TASK_NUM;count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
cmutex_init(&m[count]); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
while(i<10) { 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
gettimeofday(&t1,NULL); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(count=0;count<TASK_NUM;count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(thread_count=0;thread_count<THREAD_PER_TASK;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread_count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
c[count][thread_count] = cthread_init(test,4096,1,count); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(count=0;count<TASK_NUM;count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(thread_count=0;thread_count<THREAD_PER_TASK;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread_count++)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
cthread_run(c[count][thread_count]);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(count=0;count<TASK_NUM;count++)
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
for(thread_count=0;thread_count<THREAD_PER_TASK;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
thread_count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
cthread_join(c[count][thread_count]); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
gettimeofday(&t2,NULL); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
printf("Main Thread:time cost:%f, Granularity:%d
\backslash
n",
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
calculate(t1,t2),GRANULARITY); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
i++; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
GRANULARITY = GRANULARITY + STEP;
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
}
\end_layout

\begin_layout Standard
}
\end_layout

\end_inset

We define the 
\emph on
speedup 
\emph default
to be the ratio of the time elapsed when using pthread's mutex to the time
 elapsed when using our user-level mutex.
 
\begin_inset Formula \[
speedup\;=\;\frac{T_{p}}{T_{u}}\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Benchmarks of the system when using different mutexes
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename mutex.eps
	scale 60
	rotateAngle -90
	rotateOrigin leftTop

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Speedup of Mutexes
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename mutex_speedup.eps
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
From the results, we can see that on average, the performance of the system
 when using the user-level mutex is twice that when using pthread's mutex.
 This is because user-level mutexes never block the kernel threads.
 In fact, in the best case, it is possible that when using pthread's mutex,
 each kernel picks up a different task to do, therefore, there is no contention
 on these mutexes.
 In this case, we can still get the same performance as with user-level
 mutexes.
 However, in the worst case these tasks will be processed one by one in
 a strictly sequential manner, i.e.
 we do not benefit from the other CPU at all.
 This happens when the two kernel threads always try to work on the same
 task, so one of them is always blocked.
 Our testing machine is a dualcore machine, but on a 4-processor machine,
 we expect that the speed up would be close to 4 when there are more than
 four user-level threads working on each critical section.
 
\end_layout

\begin_layout Standard
Another benchmark is to measure the performance of the function 
\emph on
Getmutex
\emph default
 and 
\emph on
Releasemutex
\emph default
 when the mutex is not under contention.
 In this case, it is not enough to time a single function call to 
\emph on
Getmutex
\emph default
 since the time of executing the function is not large enough to compensate
 the time that is cost by calling the function 
\emph on
gettimeofday()
\emph default

\begin_inset LatexCommand cite
key "21"

\end_inset

.
 In order to measure the benchmark accurately, we have to perform a large
 number of function call to 
\emph on
Getmutex
\emph default
, then calculate the average time for a single call.
 However, this approach is not valid, because once we call 
\emph on
Getmutex
\emph default
, it will lock the mutex.
 Hence, we call 
\emph on
Getmutex
\emph default
 followed by a call to 
\emph on
Releasemutex
\emph default
, and we use a loop with 1000000 iterations to execute such a pair, and
 then calculate the average time for a single pair.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Benchmark for Getmutex and Releasemutex(
\emph on
ns
\emph default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~

\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="3">
<features>
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Pthread mutex
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Lock-based mutex
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Lock-free mutex
\end_layout

\end_inset
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
74
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
95
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
127
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
As we can see, the lock-free mutex is slower than the lock-based mutex for
 the case in which there is no contention, this is reasonable because the
 lock-free mutex uses a lot of expensive atomic operations like 
\emph on
Fetch_And_Add
\emph default
, 
\emph on
Compare_And_Swap
\emph default
 and 
\emph on
Double_Compare_And_Swap
\emph default
.
 In addition, the algorithm is also more complicated, while in contrast,
 the lock-based mutex just uses 
\emph on
Swap
\emph default
 and is therefore simpler.
 The pthread mutex is the fastest for the uncontended case, because Linux
 2.6 series kernels features a new technique called futex
\begin_inset LatexCommand cite
key "6,30"

\end_inset

 (fast user space mutex).
 Prior to Linux 2.6, a call to 
\emph on
pthread_mutex_lock
\emph default
 had to enter the kernel and operate on the pthread mutex, then return to
 user mode even the mutex is not under contention.
 But by using futexes, all operation will remain in user mode for uncontended
 case and the pthread mutex on SMP system is also implemented though spin
 locks.
 The code is written directly assembly language and it is manually optimized,
 that is why it is the fastest.
 
\end_layout

\begin_layout Section
Benchmarks for semaphores
\end_layout

\begin_layout Standard
We use the same algorithm as the one used in the above section to measure
 the impact of user-level semaphores to the performance of the SMASH system,
 the only thing changed is that in this case we use semaphores initialized
 to some number to protect the critical section.
 
\end_layout

\begin_layout Standard
Due to the hardware limit, we are not able to measure the benchmark for
 a semaphore whose counter was initialized larger than one, because we only
 have a dual core machine, hence SMASH will only create two kernel threads
 and all user-level threads are run by these two kernel threads.
 So if a semaphore is initialized to a number larger than 1, there will
 not be any contention on the semaphore.
 As a result, we only conducted the benchmark with semaphores initialized
 with 1, but in this case, the semaphores behave just as mutexes, hence
 we have similar result patterns as above.
\end_layout

\begin_layout Standard
In fact, on the SMASH system, no matter how many user-level threads access
 a semaphore, if the semaphore is initialized to a number smaller than the
 number of CPUs (i.e.
 the number of kernel threads), then there will not be any contention on
 it since the number of threads accessing the semaphore concurrently is
 always smaller than the initial number of the semaphore's counter.
 However, our design is not limited to SMASH, it can be used in other contexts,
 and we do expect that in a system with a large set of CPUs, our lock-free
 design will perform better than the lock-based one because it reduces the
 memory contention.
 Even on a uniprocessor system, to implement a kind of system semaphore
 for kernel threads like pthreads on Linux, our design may also be a better
 solution than simply disabling the interrupts when a kernel thread accesses
 a semaphore, because disabling interrupts is also very expensive on uniprocesso
r systems.
\end_layout

\begin_layout Standard
In addition, we used the same mechanism in the previous section to conduct
 the benchmarks of the lock-free, lock-based semaphores and the system semaphore.
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Benchmarks of semaphores(
\emph on
ns
\emph default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~

\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="3">
<features>
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Lock-free
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Lock-based
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
System
\end_layout

\end_inset
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
90
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
96
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
383
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset

 From the result, we can see the lock-free implementation slightly outperformed
 the lock-based implementation and the system semaphore is the slowest.
 This is because operations on system semaphores are done by using system
 calls which are expensive.
\end_layout

\begin_layout Section
Benchmarks for message queues
\end_layout

\begin_layout Standard
In this section, we are going to measure and compare the performance on
 the lock-based and lock-free message queues.
 We conducted the benchmarks for sending messages and for receiving messages.
 To conduct the former one, we created 25000 user-level threads, each of
 which sends a message to the message queue.
 To conduct the latter, we use a thread to dequeue a large number of messages
 which are pre-enqueued into the message queue, hence in this case the thread
 receiving messages never blocks.
 Finally, the average time of a signal operation is calculated.
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Algorithm for the benchmark of sending messages
\end_layout

\end_inset


\end_layout

\begin_layout Standard
#define THREAD_NUM 25000 
\end_layout

\begin_layout Standard
double calculate (struct timeval t1, struct timeval t2) { 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
return ((double)(t2.tv_sec - t1.tv_sec))*1000000 + (t2.tv_usec - t1.tv_usec);
 
\end_layout

\begin_layout Standard
} 
\end_layout

\begin_layout Standard
struct lockfree_message_queue q; 
\end_layout

\begin_layout Standard
void test(cthread * ct) { 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
send_message((void*)1,&q); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
cthread_stop(); 
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard
void cthread_main() { 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
int count; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
struct timeval t1,t2; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
cthread * c[THREAD_NUM]; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
message_queue_init(&q); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
for(count=0;count<THREAD_NUM;count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
c[count] = cthread_init(test,4096,0); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
gettimeofday(&t1,NULL); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
for(count=0;count<THREAD_NUM;count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
cthread_run(c[count]); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
for(count=0;count<THREAD_NUM;count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
cthread_join(c[count]); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
gettimeofday(&t2,NULL); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
printf("time cost:%f
\backslash
n",calculate(t1,t2)); 
\end_layout

\begin_layout Standard
} 
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Algorithm for the benchmark of receiving messages
\end_layout

\end_inset


\end_layout

\begin_layout Standard
#define NUM 50000
\end_layout

\begin_layout Standard
double calculate (struct timeval t1, struct timeval t2) { 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
return ((double)(t2.tv_sec - t1.tv_sec))*1000000 + (t2.tv_usec - t1.tv_usec);
 
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard
struct lockfree_message_queue q; 
\end_layout

\begin_layout Standard
void test(cthread *ct) { 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
int count; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
struct timeval t1,t2; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
for(count=0;count<NUM;count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
send_message((void*)1,&q); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
gettimeofday(&t1,NULL); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
for(count=0;count<NUM;count++) 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
fetch_message(&q); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
gettimeofday(&t2,NULL); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
printf("Total time cost:%f
\backslash
nTime Per Operation:%f
\backslash
n",calculate(t1,t2),calculate(t1,t2)/NUM);
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
cthread_stop(); 
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard
void cthread_main() { 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
int count; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
cthread * c; 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
message_queue_init(&q); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
c = cthread_init(test,40960,0); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
cthread_run(c); 
\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
cthread_join(c); 
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
Results of message queues(
\emph on
ns
\emph default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~
\InsetSpace ~

\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="2">
<features>
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Enqueue operation
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard

\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Lock-based
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Lock-free
\end_layout

\end_inset
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
1321
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
1257
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="2">
<features>
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Dequeue operation
\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Lock-based
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Lock-free
\end_layout

\end_inset
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
133
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
135
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset

From the result, we can see that the difference between the lock-based approach
 and the lock-free approach is not significant for both sending messages
 and receiving messages.
 In fact, the dominating factor for the performance of our message queues
 is the performance of the FIFO queues used to store messages.
 Although according to 
\begin_inset LatexCommand cite
key "2"

\end_inset

, the lock-free FIFO queue we used is much faster than the FIFO queue with
 spin locks when a large number of threads access the queue concurrently.
 In our case, since we have only two kernel threads running concurrently
 when sending messages, and only one thread is running when receiving messages
 (in which case, there is no contention at all), it is not surprising that
 these two queues give similar performance.
 Another thing to note is from the result is that sending a message is much
 more expensive than dequeuing a message from the queue.
 However, this is not accurate, because when we were conducting the benchmark
 for sending messages, we timed both the message sending operations in each
 user-level thread, and the operation that the main thread of SMASH joins
 these 25000 user-level threads and the thread scheduling operations, which
 are quite expensive.
 On the other hand, when we conducted the benchmark for the receiving operation,
 we only timed the dequeuing operation.
 
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
In this chapter, we measured the performance of the user-level inter-thread
 communication constructs implemented in this project, and some improvements
 have been shown by the results.
 However, in general the lock-free implementations do not outperform significant
ly the lock-based implementations.
 It is suspected that this is due to the limitation of the hardware used
 to conduct the experiments.
 To give a more comprehensive analysis, SMP systems with more CPUs are needed
 for the testing.
 
\end_layout

\begin_layout Chapter
Conclusion and Future work
\end_layout

\begin_layout Standard
In this project, we have implemented user-level mutexes, semaphores, message
 queues and communication channels for SMASH.
 From the results we can see that by implementing inter-thread communication
 constructs at the user-level, the overall performance of SMASH can be significa
ntly improved.
 In fact, it is a defect that in a user-level thread system like SMASH,
 the inter-thread communications still use the kernel, since one of the
 major advantage of user-level threads over kernel threads is that there
 is no vertical switch in context switches.
 Another advantage of implementing these constructs at the user level is
 that when a user-level thread is blocked on some construct, the underlying
 kernel threads are still able to schedule other user-level threads (if
 any) to run.
 In contrast, kernel-level inter-thread communication constructs always
 block the kernel threads, and as a result, a single user-level thread will
 block the underlying kernel thread as well hence no other user-level threads
 can run on that kernel thread, which wastes a lot of computational resources.
 
\end_layout

\begin_layout Standard
In addition, each of these constructs has two different implementations:
 the lock-based implementation in which critical sections are protected
 by spin locks, and the lock-free implementation in which a lock-free algorithm
 is used to synchronize the threads accessing them.
 It is believed that lock-free algorithms perform better as the number of
 concurrent accesses increases because compared to spin locks, they have
 lower memory contention.
 Additionally, spin locks also waste a lot of CPU time.
 So it is expected that our lock-free implementations will perform better
 than lock-based implementation of these constructs.
 However, to show that, we need an SMP machines with a sufficient number
 of CPUs, whereas unfortunately, only a dual core machine was available
 during this project, so it was not possible to give a reasonably good result.
\end_layout

\begin_layout Section
Futher work
\end_layout

\begin_layout Standard
There is still a lot of space for further improvement of the lock-free algorithm
s we designed.
 
\end_layout

\begin_layout Itemize
In the lock-free mutex and lock-free semaphores, in order to solve the 
\emph on
lost-wake-up
\emph default
 problem, indefinite loops are used to dequeue waiting threads in their
 waiting queues, but dequeuing is still relatively expensive.
 A further refinement is to move the dequeue operation out of these indefinite
 loops, or to avoid these loops altogether, in which case, these constructs
 are almost wait-free, but they are not entirely wait-free because their
 waiting queues are not wait-free.
 
\end_layout

\begin_layout Itemize
In our current implementation of message queues, an enqueue operation creates
 a new node with 
\emph on
malloc
\emph default
 and a dequeue operation destroys the node with 
\emph on
free
\emph default
, but these operations are costly, so a user-level memory management system
 should be implemented.
 
\end_layout

\begin_layout Itemize
Our message queue can only be used to send discrete messages, they can not
 be used to send byte streams like sockets.
 In the future, a socket-like construct should also be implemented for streaming.
 
\end_layout

\begin_layout Itemize
In the current design of the lock-based channels, channel input and channel
 output lock the entire set of channels that participate in the communication
 then loop over them.
 As a result, as the number of channels increases, the lock-granularity
 also increases, causing degradation of the overall performance.
 A possible improvement is to reduce the lock granularity.
 A new lock-based channel with fine-grained locks should be designed.
 Vella described a channel with alternative support for KRoC on uniprocessor
 systems in 
\begin_inset LatexCommand cite
key "15"

\end_inset

, and it is expected that the design can be ported to SMASH with some critical
 sections protected by fine-grained spin locks.
 
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
In this project, we implemented several user-level inter-thread communication
 constructs for SMASH, and gained some improvements to the overall performance
 of the SMASH system.
 Additionally, we also exploited lock-free algorithms by implementing the
 constructs we introduced in a lock-free manner.
 Although due to the limitation of the hardware we currently have, the advantage
 of these lock-free implementations can not be shown, we still believe that
 lock-free algorithms perform better than lock-based algorithms when a multiproc
essor system is under high contention.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "1"
key "1"

\end_inset

Andrei Alexandrescu and Maged M.
 Michael, Lock-free Data Structure with Hazard Pointers.
 Technical report.
 C/C++ Users Journal, December, 2004.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "2"
key "2"

\end_inset

Dominique Fober, Yann Qrlarey, Stephane Letz.
 Lock Free Techniques for Concurrent Access to Shared Objects.
 Technical report.
 GRAME - Computer Music Research Lab.
 2001.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "3"
key "3"

\end_inset

Edya Ladan-Mozes and Nir Shavit, An Optimistic Approach to Lock-free FIFO
 Queues, page 117-131, Distributed Computing.
 Springer Berlin/Heidelberg.
 ISBN 978-3-540-23306-0.
 2004.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "4"
key "4"

\end_inset

H.
 Gao and W.H.
 Hesselink.
 A general lock-free algorithm using compare-and-swap.
 Volume 205, issue 2, pages 225-241.
 Information and Computation.
 Academic Press, Inc.
 2007
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "5"
key "5"

\end_inset

Gregory R.
 Andrews, Foundations of Multithreaded, Parallel, and Distributed Programming.
 Addison Wesley Longman.
 Inc.
 ISBN 0-201-35752-6.
 2000.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "6"
key "6"

\end_inset

Hubertus Franke and Rusty Russell.
 Fuss, Futexes and Furwocks: Fast Userlevel Locking in Linux.
 Ottawa Linux Symposium.
 2002.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "7"
key "7"

\end_inset

IBM, IBM System/370 Extended Architecture, Principles of Operation, 1983.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "8"
key "8"

\end_inset

Jochen Liedtke, Toward Real Microkernels.
 Communications of the ACM, Vol.39, No.9, 1996.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "9"
key "9"

\end_inset

Jochen Liedtke, On 
\begin_inset Formula $\mu-Kernel$
\end_inset

 Construction.
 The 15th ACM Symposium on Operating System Principles.
 1995.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "10"
key "10"

\end_inset

Joseph Cordina, Fast Multi-Threading on Shared Memory Multiprocessors.
 B.Sc.(Hons) dissertation, Department of Computer Science and Artificial Intellige
nce, University of Malta, 2000.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "11"
key "11"

\end_inset

Joseph Cordina, Stephen Fenech and Gordon J.
 Pace, Model Checking Concurrent Assembly Algorithms.
 Technical report, 5th Computer Science Annual Workshop, Malta, 2007.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "12"
key "12"

\end_inset

John D.
 Valois, Lock-free Data Structures.
 PhD thesis, Rensselaer Polytechnic Institute, Troy, New York, USA, 1995.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "13"
key "13"

\end_inset

John M.
 Mellor-Crummey and Michael L.
 Scott, Synchronization Without Contention.
 The Fourth International Conference on Architectural Support for Programming
 Languages and Operating Systems, pages 269-278.
 April 8-11, 1991.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "14"
key "14"

\end_inset

Jonathan S.
 Shapiro, Vulnerabilities in Synchronous IPC Designs, page 251, SP'03: Proceedin
gs of the 2003 IEEE Symposium on Security and Privacy.
 IEEE Computer Society, ISBN 0-7695-1940-7.
 2003.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "15"
key "15"

\end_inset

Kevin Vella.
 Seamless parallel computing on heterogeneous networks of mutiprocessor
 workstations.
 PhD thesis, University of Kent at Canterbury, 1998.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "16"
key "16"

\end_inset

Kurt Debattista, High Performance Thread Scheduling on Share Memory Multiprocess
ors.
 Master's thesis, University of Malta, 2001.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "17"
key "17"

\end_inset

Lawrence Kesteloot, A Survey of Mutual-Exclusion Algorithms for Multiprocessor
 Operating Systems.
 1995.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "18"
key "18"

\end_inset

Maged M.
 Michael and Michael L.
 Scott, Simple, Fast, and Practical Non-Blocking and Blocking Concurrent
 Queue Algorithms.
 The 15th Annual ACM Symposium on Principles of Distributed Computing, pages
 267-275.
 1996.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "19"
key "19"

\end_inset

Maged M.
 Michael, Practical Lock-free and Wait-free LL/SC/VL Implementation Using
 64-Bit CAS, Page 144-158.
 Distributed Computing.
 ISBN 978-3-540-23306-0, Springer Berlin/Heidelberg.
 2004.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "20"
key "20"

\end_inset

Maged M.
 Michael, Hazard Pointers: Safe Memory Reclamation for Lock-free Objects.
 IEEE Transactions on Parallel and Distributed Systems, Vol 15, No.6, 2004.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "21"
key "21"

\end_inset

Marc J.
 Rochkind, Advanced UNIX Programming.
 Second Edition.
 ISBN 7-302-12645-3.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "22"
key "22"

\end_inset

Marcel Boosten, Fine-Grain Parallel Processing on a Commodity Platform:
 a Solution for ATLAS Second Level Trigger.
 PhD thesis.
 Technische Universiteit Eindhoven.
 ISBN 90-386-0642-7.
 2003.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "23"
key "23"

\end_inset

Marcel Boosten, MESH: Messaging and Scheduling for Fine Grained Parallel
 Processing on Commodity Platforms.
 Page 263-276.
 Architectures, Languages and Techniques for Concurrent Systems: WoTug-22.
 IOS Press.
 ISBN 978-90-5199-480-3.
 1999.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "24"
key "24"

\end_inset

Mark Moir, Daniel Nussbaum, Ori Shalev, Nir Shavit.
 Using Elimination to Implement Scalable and Lock-free FIFO Queues.
 SPAA'05, Las Vegas, Nevada, USA.
 July 18-25, 2005.
 ACM 1-58113-986-1/05/0007.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "25"
key "25"

\end_inset

Maurice Herlihy, Wait-free Synchronization, ACM Transactions on Programming
 Languages and System.
 Vol.11, No.1,1991.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "26"
key "26"

\end_inset

Silberschatz, Galvin and Gagne.
 Operating System Concepts.
 John Wiley & Sons, Inc.
 ISBN 0-471-69466-5 
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "27"
key "27"

\end_inset

Simon Doherty, Maurice Herlihy, Victor Luchangco and Mark Moir.
 Bring Practical Lock-Free Synchronization to 64-Bit Applications.
 PODC' 04, July 25-28, St.
 Jonh's, Newfoundland, Canada.
 ACM 1-58113-802-4/04/0007.
 2004.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "28"
key "28"

\end_inset

SGS-THOMSON Microelectronics Limited, Occam 2.1 Reference Manual, 1995.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "29"
key "29"

\end_inset

Thorsten Scheuermann, Evolution in Microkernel Design.
 COMP 242.
 2002.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "30"
key "30"

\end_inset

Ulrich Drepper, Futexes Are Tricky.
 Red Hat, Inc.
 2008.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "31"
key "31"

\end_inset

Uresh Vahalia, Unix Internals: The New Frontiers.
 Prentice Hall.
 ISBN 0-13-101908-2.
 1995.
\end_layout

\begin_layout Bibliography
\begin_inset LatexCommand bibitem
label "32"
key "32"

\end_inset

Yi Zhang, Non-blocking Shared Data Structure for Shared Memory Multiprocessor.
 Thesis for the Degree of Licentiate of Philosophy.
 Goteborg University, Sweden.
 2001.
\end_layout

\end_body
\end_document
